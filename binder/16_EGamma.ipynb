{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook\n",
    "- uses the `hwwprocessor_nocuts` processor which doesn't apply any cuts but saves the cuts as bools for us to test and cross-check\n",
    "- runs over EGamma sample... one root file...\n",
    "- makes stacked hist plots to compare the different cuts\n",
    "- makes 2d plots to cross-check any pair of variables (e.g. lep_pt vs jet_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import uproot\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema, BaseSchema\n",
    "from coffea import nanoevents\n",
    "from coffea import processor\n",
    "import time\n",
    "\n",
    "import argparse\n",
    "import warnings\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from collections import defaultdict\n",
    "import pickle as pkl\n",
    "import pyarrow as pa\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "from typing import List, Optional\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "from coffea import processor\n",
    "from coffea.nanoevents.methods import candidate, vector\n",
    "from coffea.analysis_tools import Weights, PackedSelection\n",
    "from boostedhiggs.utils import match_HWW\n",
    "from boostedhiggs.btag import btagWPs\n",
    "from boostedhiggs.btag import BTagCorrector\n",
    "\n",
    "import hist as hist2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import mplhep as hep\n",
    "from hist.intervals import clopper_pearson_interval\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Found duplicate branch \")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "np.seterr(invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = '/0-1'\n",
    "channels=['ele', 'mu', 'had']\n",
    "sample = \"EGamma\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: EGamma\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506c9e354eeb4df9af598cdeb0aab8c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing:   0%|          | 0/1 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feaa29bf4bd5412cbc13ab64e0f64177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/8 [00:00<?, ?chunk/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/coffea-env/lib/python3.7/site-packages/awkward/_connect/_numpy.py:210: RuntimeWarning: divide by zero encountered in log\n",
      "  *[nplike.asarray(x) for x in inputs], **kwargs\n"
     ]
    }
   ],
   "source": [
    "# define the configuration and processor\n",
    "\n",
    "fileset = {}\n",
    "print(f\"Processing: {sample}\")\n",
    "fileset[sample] = [f\"../datafiles/{sample}/{sample}.root\"]\n",
    "\n",
    "outfiles = \"./\" + sample + \"/\"\n",
    "\n",
    "# remove output directory to store fresh samples\n",
    "if os.path.exists(outfiles):\n",
    "    shutil.rmtree(outfiles)\n",
    "\n",
    "from boostedhiggs.hwwprocessor_nocuts import HwwProcessor_nocuts\n",
    "p = HwwProcessor_nocuts(year='2017', channels=channels, output_location=outfiles + job_name)\n",
    "\n",
    "executor = processor.IterativeExecutor(status=True)\n",
    "run = processor.Runner(\n",
    "    executor=executor, savemetrics=True, schema=nanoevents.NanoAODSchema, chunksize=10000\n",
    ")\n",
    "\n",
    "out, metrics = run(\n",
    "fileset, \"Events\", processor_instance=p\n",
    ")\n",
    "\n",
    "# dump to pickle\n",
    "filehandler = open(outfiles + job_name + '.pkl', \"wb\")\n",
    "pkl.dump(out, filehandler)\n",
    "filehandler.close()\n",
    "\n",
    "# merge parquet\n",
    "for ch in channels:\n",
    "    data = pd.read_parquet(outfiles + job_name + ch + '/parquet')\n",
    "    data.to_parquet(outfiles + job_name + '_' + ch + '.parquet')\n",
    "\n",
    "    # remove old parquet files\n",
    "#     os.system('rm -rf ' + outfiles + job_name + ch)\n",
    "\n",
    "    data_jets = pd.read_parquet(outfiles + job_name + '/jets/' + ch + '/parquet')\n",
    "    data_jets.to_parquet(outfiles + job_name + '_jets_' + ch + '.parquet')\n",
    "\n",
    "# remove old parquet files\n",
    "# os.system('rm -rf ' + outfiles + job_name)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "metadata = {}\n",
    "\n",
    "data[sample] = {}\n",
    "\n",
    "outfiles = \"./\" + sample + \"/\"\n",
    "\n",
    "for ch in channels:\n",
    "    data[sample][ch] = pq.read_table(outfiles + job_name + '_' + ch + '.parquet').to_pandas()\n",
    "\n",
    "with open(outfiles + job_name + '.pkl', 'rb') as f:\n",
    "    metadata[sample] = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['EGamma']['ele']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['EGamma']['mu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['EGamma']['had']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No cuts applied yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D-histograms with single axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'lep_pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/envs/coffea-env/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/coffea-env/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/coffea-env/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'lep_pt'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d7/p4v84gls67vdp9_q2rkkvkch0000gn/T/ipykernel_46429/866746136.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mhist2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lep_pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lep_pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n\u001b[0;32m----> 4\u001b[0;31m h.fill(data[sample]['ele']['lep_pt']\n\u001b[0m\u001b[1;32m      5\u001b[0m       )\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/coffea-env/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/coffea-env/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'lep_pt'"
     ]
    }
   ],
   "source": [
    "h = hist2.Hist(\n",
    "    hist2.axis.Regular(100,0, 500, name='lep_pt', label='lep_pt', flow=True),\n",
    ")\n",
    "h.fill(data[sample]['ele']['lep_pt']\n",
    "      )\n",
    "\n",
    "odir = sample + \"/plots/jets\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "hep.histplot(h, ax=ax)\n",
    "# ax.set_xlabel(f\"{'btag_max'}\")\n",
    "ax.set_title(f'ele channel for \\n {sample}')\n",
    "hep.cms.lumitext(f\"'2017' (13 TeV)\", ax=ax)\n",
    "hep.cms.text(\"Work in Progress\", ax=ax)\n",
    "\n",
    "if not os.path.exists(f'{odir}/'):\n",
    "    os.makedirs(f'{odir}/')\n",
    "\n",
    "plt.savefig(f'{odir}/lep_pt_wth_btag_threshold.pdf')\n",
    "## 1D-histograms with single axis:    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register the cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_cuts = ['lep_pt', 'oneElectron', 'notaus_ele', 'ElectronIsolation', 'mt_lep_met']\n",
    "normal_plus_btag = ['lep_pt', 'oneElectron', 'notaus_ele', 'ElectronIsolation', 'mt_lep_met', 'anti_bjettag']\n",
    "normal_plus_dR = ['lep_pt', 'oneElectron', 'notaus_ele', 'ElectronIsolation', 'mt_lep_met', 'leptonInJet']\n",
    "normal_plus_btag_plus_dR = ['lep_pt', 'oneElectron', 'notaus_ele', 'ElectronIsolation', 'mt_lep_met', 'anti_bjettag', 'leptonInJet']\n",
    "\n",
    "# make a cut dict to map the \"cut label\" to the actual cut\n",
    "cut_dict = {}\n",
    "cut_dict[sample] = {'lep_pt':            (data[sample]['ele']['leptonKin']>40),\n",
    "                    'oneElectron':       (data[sample]['ele']['oneElectron']),\n",
    "                    'notaus_ele':        (data[sample]['ele']['notaus_ele']),''\n",
    "                    'ElectronIsolation': (data[sample]['ele']['ElectronIsolation']==1),\n",
    "                    'mt_lep_met':        (data[sample]['ele']['mt_lep_met']==1),\n",
    "                    'anti_bjettag':      (data[sample]['ele']['anti_bjettag']==1),\n",
    "                    'leptonInJet':       (data[sample]['ele']['leptonInJet']==1)\n",
    "                   }\n",
    "\n",
    "def apply_cuts(sample, cuts = ['lep_pt', 'oneElectron', 'notaus_ele', 'ElectronIsolation', 'mt_lep_met', 'anti_bjettag', 'leptonInJet']):\n",
    "\n",
    "    '''\n",
    "    takes as input a list of cut names (any of the \"cutdict\" keys defined above)\n",
    "    returns output as a boolean array to apply on the events\n",
    "    '''\n",
    "    for i, cut in enumerate(cuts):\n",
    "        if i==0:\n",
    "            combined_bool = cut_dict[sample][cut]\n",
    "        else:\n",
    "            combined_bool = pd.concat([combined_bool,cut_dict[sample][cut]], axis=1)\n",
    "    \n",
    "    if len(cuts)==1:\n",
    "        return combined_bool\n",
    "    return combined_bool.all(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# btag vs lep_pt\n",
    "h = hist2.Hist(\n",
    "    hist2.axis.Regular(100,0, 500, name='lep_pt', label='lep_pt', flow=True),    \n",
    "    hist2.axis.Regular(100,0, 1, name='lep_fj_dr', label='lep_fj_dr', flow=True),\n",
    ")\n",
    "\n",
    "h.fill(data[sample]['ele']['lep_pt'], data[sample]['ele']['lep_fj_dr'],\n",
    ")\n",
    "\n",
    "odir = sample + \"/plots/\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "hep.hist2dplot(h, ax=ax, norm=matplotlib.colors.LogNorm(vmin=1e-3))    \n",
    "ax.set_title(f'{sample}')\n",
    "hep.cms.lumitext(f\"'2017' (13 TeV)\", ax=ax)\n",
    "hep.cms.text(\"Work in Progress\", ax=ax)\n",
    "\n",
    "\n",
    "if not os.path.exists(f'{odir}/'):\n",
    "    os.makedirs(f'{odir}/')\n",
    "\n",
    "plt.savefig(f'{odir}/lep_fj_dr_vs_lep_pt_before_cuts.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_cuts = ['lep_pt', 'oneElectron', 'notaus_ele', 'ElectronIsolation', 'mt_lep_met']\n",
    "normal_plus_btag = ['lep_pt', 'oneElectron', 'notaus_ele', 'ElectronIsolation', 'mt_lep_met', 'anti_bjettag']\n",
    "normal_plus_dR = ['lep_pt', 'oneElectron', 'notaus_ele', 'ElectronIsolation', 'mt_lep_met', 'leptonInJet']\n",
    "normal_plus_btag_plus_dR = ['lep_pt', 'oneElectron', 'notaus_ele', 'ElectronIsolation', 'mt_lep_met', 'anti_bjettag', 'leptonInJet']\n",
    "\n",
    "\n",
    "cut_choice = normal_plus_btag_plus_dR\n",
    "\n",
    "# btag vs lep_pt\n",
    "h = hist2.Hist(\n",
    "    hist2.axis.Regular(100,0, 500, name='lep_pt', label='lep_pt', flow=True),    \n",
    "    hist2.axis.Regular(100,0, 1.5, name='lep_fj_dr', label='lep_fj_dr', flow=True),\n",
    ")\n",
    "\n",
    "h.fill(data[sample]['ele']['lep_pt'][apply_cuts(sample, cut_choice)], data[sample]['ele']['lep_fj_dr'][apply_cuts(sample, cut_choice)],\n",
    ")\n",
    "\n",
    "odir = sample + \"/plots/\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "hep.hist2dplot(h, ax=ax, norm=matplotlib.colors.LogNorm(vmin=1e-3))    \n",
    "ax.set_title(f'{sample}')\n",
    "hep.cms.lumitext(f\"'2017' (13 TeV)\", ax=ax)\n",
    "hep.cms.text(\"Work in Progress\", ax=ax)\n",
    "\n",
    "if not os.path.exists(f'{odir}/'):\n",
    "    os.makedirs(f'{odir}/')\n",
    "\n",
    "plt.savefig(f'{odir}/lep_fj_dr_vs_lep_pt_after_cuts.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# btag vs lep_pt\n",
    "h = hist2.Hist(\n",
    "    hist2.axis.Regular(100,0, 500, name='lep_pt', label='lep_pt', flow=True),    \n",
    "    hist2.axis.Regular(100,0, 500, name='fj_pt', label='fj_pt', flow=True),\n",
    ")\n",
    "\n",
    "h.fill(data[sample]['ele']['lep_pt'], data[sample]['ele']['fj_pt']\n",
    ")\n",
    "\n",
    "odir = sample + \"/plots/\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "hep.hist2dplot(h, ax=ax, norm=matplotlib.colors.LogNorm(vmin=1e-3))    \n",
    "ax.set_title(f'{sample}')\n",
    "hep.cms.lumitext(f\"'2017' (13 TeV)\", ax=ax)\n",
    "hep.cms.text(\"Work in Progress\", ax=ax)\n",
    "\n",
    "\n",
    "if not os.path.exists(f'{odir}/'):\n",
    "    os.makedirs(f'{odir}/')\n",
    "\n",
    "plt.savefig(f'{odir}/fj_pt_vs_lep_pt_before_cuts.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_choice = normal_plus_btag_plus_dR\n",
    "\n",
    "# btag vs lep_pt\n",
    "h = hist2.Hist(\n",
    "    hist2.axis.Regular(100,0, 500, name='lep_pt', label='lep_pt', flow=True),    \n",
    "    hist2.axis.Regular(100,0, 500, name='fj_pt', label='fj_pt', flow=True),\n",
    ")\n",
    "\n",
    "h.fill(data[sample]['ele']['lep_pt'][apply_cuts(sample, cut_choice)], data[sample]['ele']['fj_pt'][apply_cuts(sample, cut_choice)]\n",
    ")\n",
    "\n",
    "odir = sample + \"/plots/\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "hep.hist2dplot(h, ax=ax, norm=matplotlib.colors.LogNorm(vmin=1e-3))    \n",
    "ax.set_title(f'{sample}')\n",
    "hep.cms.lumitext(f\"'2017' (13 TeV)\", ax=ax)\n",
    "hep.cms.text(\"Work in Progress\", ax=ax)\n",
    "\n",
    "if not os.path.exists(f'{odir}/'):\n",
    "    os.makedirs(f'{odir}/')\n",
    "\n",
    "plt.savefig(f'{odir}/fj_pt_vs_lep_pt_after_cuts.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffea-env",
   "language": "python",
   "name": "coffea-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
