{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make datacard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple, Union\n",
    "\n",
    "import json\n",
    "import logging\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import sys\n",
    "import os\n",
    "import rhalphalib as rl\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "rl.util.install_roofit_helpers()\n",
    "rl.ParametericSample.PreferRooParametricHist = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMS_PARAMS_LABEL = \"CMS_HWW_semileptonic_boosted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41475.26"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year = \"2017\"   # can give \"all\"\n",
    "ch = \"mu\"\n",
    "\n",
    "with open(\"../fileset/luminosity.json\") as f:\n",
    "    LUMI = json.load(f)[ch]\n",
    "\n",
    "if year != \"all\":\n",
    "    years = [year]\n",
    "    full_lumi = LUMI[year]\n",
    "else:\n",
    "    years = [\"2016\", \"2016APV\", \"2017\", \"2018\"]\n",
    "    full_lumi = np.sum(list(LUMI.values()))\n",
    "\n",
    "full_lumi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# systematics that are NOT necessarily stored in the parquets\n",
    "sys_dict = {\n",
    "    f\"lumi_13TeV_{year}\": rl.NuisanceParameter(f'CMS_lumi_13TeV_{year}', 'lnN'),\n",
    "    \"BR_hww\": rl.NuisanceParameter(f'BR_hww', 'lnN'),\n",
    "}\n",
    "\n",
    "sys_dict_values = {\n",
    "    f\"lumi_13TeV_{year}\": (1.02 ** (LUMI[\"2017\"] / full_lumi), None),\n",
    "    \"BR_hww\": (1.0153, 0.9848)\n",
    "}\n",
    "\n",
    "# systematics that ARE stored in the parquets\n",
    "sys_from_parquets = {\n",
    "    \"mu\": {\n",
    "        \"all_samples\": {\n",
    "            \"weight_mu_btagSFlight_2017\": rl.NuisanceParameter(f'{CMS_PARAMS_LABEL}_btagSFlight_{year}', 'lnN'),\n",
    "            \"weight_mu_btagSFlight_correlated\": rl.NuisanceParameter(f'{CMS_PARAMS_LABEL}_btagSFlight_correlated', 'lnN'),\n",
    "            \"weight_mu_btagSFbc_2017\": rl.NuisanceParameter(f'{CMS_PARAMS_LABEL}_btagSFbc_{year}', 'lnN'),\n",
    "            \"weight_mu_btagSFbc_correlated\": rl.NuisanceParameter(f'{CMS_PARAMS_LABEL}_btagSFbc_correlated', 'lnN'),\n",
    "            \"weight_mu_pileup\": rl.NuisanceParameter(f'{CMS_PARAMS_LABEL}_PU_{year}', 'shape'),\n",
    "            \"weight_mu_isolation_muon\": rl.NuisanceParameter(f'CMS_mu_iso_{year}', 'lnN'),\n",
    "            \"weight_mu_id_muon\": rl.NuisanceParameter(f'CMS_mu_id_{year}', 'lnN'),\n",
    "            \"weight_mu_L1Prefiring\": rl.NuisanceParameter(f'CMS_L1Prefiring_{year}', 'lnN'),\n",
    "            \"weight_mu_trigger_iso_muon\": rl.NuisanceParameter('CMS_btagSF', 'lnN'),\n",
    "            \"weight_mu_trigger_noniso_muon\": rl.NuisanceParameter(f'{CMS_PARAMS_LABEL}_mu_trigger_{year}', 'lnN'),\n",
    "        },\n",
    "        \"HWW\": {\n",
    "            \"weight_mu_UEPS_FSR\": rl.NuisanceParameter('UEPS_FSR_ggF', 'lnN'),\n",
    "            \"weight_mu_UEPS_ISR\": rl.NuisanceParameter('UEPS_ISR_ggF', 'lnN'),\n",
    "            \"weight_mu_PDF_weight\": rl.NuisanceParameter('pdf_Higgs_ggF', 'lnN'),\n",
    "            \"weight_mu_PDFaS_weight\": rl.NuisanceParameter('pdfAS_Higgs_ggF', 'lnN'),\n",
    "            \"weight_mu_scalevar_3pt\": rl.NuisanceParameter(f'{CMS_PARAMS_LABEL}_scale_pt_3_{year}', 'lnN'),\n",
    "            \"weight_mu_scalevar_7pt\": rl.NuisanceParameter(f'{CMS_PARAMS_LABEL}_scale_pt_7_{year}', 'lnN'),\n",
    "        },\n",
    "        \"WJetsLNu\": {\n",
    "            \n",
    "        },\n",
    "        \"TTbar\": {\n",
    "            \n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_to_num(var, nom, clip=1.5):\n",
    "    nom_rate = np.sum(nom)\n",
    "    var_rate = np.sum(var)\n",
    "\n",
    "    if abs(var_rate/nom_rate) > clip:\n",
    "        var_rate = clip*nom_rate\n",
    "\n",
    "    if var_rate < 0:\n",
    "        var_rate = 0\n",
    "\n",
    "    return var_rate/nom_rate\n",
    "\n",
    "def get_template(sample, ptbin):\n",
    "    return (\n",
    "        hists_templates[\"cat1_sr\"][{\"samples\": sample, \"systematic\": \"Nominal\", \"fj_pt\": ptbin}].values(),\n",
    "        massbins,\n",
    "        \"reco_higgs_m\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(\"hists_templates.pkl\", \"rb\") as f:\n",
    "    hists_templates = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat1_sr': Hist(\n",
       "   StrCategory(['WJetsLNu', 'TTbar', 'HWW', 'QCD', 'Data'], growth=True, name='samples'),\n",
       "   StrCategory(['Nominal', 'weight_mu_btagSFlight_2017Up', 'weight_mu_btagSFlight_2017Down', 'weight_mu_btagSFlight_correlatedUp', 'weight_mu_btagSFlight_correlatedDown', 'weight_mu_btagSFbc_2017Up', 'weight_mu_btagSFbc_2017Down', 'weight_mu_btagSFbc_correlatedUp', 'weight_mu_btagSFbc_correlatedDown', 'weight_mu_pileupUp', 'weight_mu_pileupDown', 'weight_mu_isolation_muonUp', 'weight_mu_isolation_muonDown', 'weight_mu_id_muonUp', 'weight_mu_id_muonDown', 'weight_mu_L1PrefiringUp', 'weight_mu_L1PrefiringDown', 'weight_mu_trigger_iso_muonUp', 'weight_mu_trigger_iso_muonDown', 'weight_mu_trigger_noniso_muonUp', 'weight_mu_trigger_noniso_muonDown', 'weight_mu_d1K_NLOUp', 'weight_mu_d1K_NLODown', 'weight_mu_d2K_NLOUp', 'weight_mu_d2K_NLODown', 'weight_mu_d3K_NLOUp', 'weight_mu_d3K_NLODown', 'weight_mu_d1kappa_EWUp', 'weight_mu_d1kappa_EWDown', 'weight_mu_W_d2kappa_EWUp', 'weight_mu_W_d2kappa_EWDown', 'weight_mu_W_d3kappa_EWUp', 'weight_mu_W_d3kappa_EWDown', 'weight_mu_UEPS_FSRUp', 'weight_mu_UEPS_FSRDown', 'weight_mu_UEPS_ISRUp', 'weight_mu_UEPS_ISRDown', 'weight_mu_PDF_weightUp', 'weight_mu_PDF_weightDown', 'weight_mu_PDFaS_weightUp', 'weight_mu_PDFaS_weightDown', 'weight_mu_scalevar_3ptUp', 'weight_mu_scalevar_3ptDown', 'weight_mu_scalevar_7ptUp', 'weight_mu_scalevar_7ptDown'], growth=True, name='systematic'),\n",
       "   Variable([200, 300, 450, 650, 1200], name='fj_pt', label='Jet $p_T$ [GeV]'),\n",
       "   Variable([40, 61, 82, 103, 124, 145, 166, 187, 208, 229], name='rec_higgs_m', label='Higgs reconstructed mass [GeV]'),\n",
       "   storage=Double()) # Sum: 181037579.6788259 (269646768.9288989 with flow)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hists_templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create datacard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptbins = hists_templates[\"cat1_sr\"].axes[2].edges\n",
    "npt = len(ptbins) - 1\n",
    "\n",
    "massbins = hists_templates[\"cat1_sr\"].axes[3].edges\n",
    "mass = rl.Observable('reco_higgs_m', massbins)\n",
    "\n",
    "# here we derive these all at once with 2D array\n",
    "ptpts, masspts = np.meshgrid(ptbins[:-1] + 0.3 * np.diff(ptbins), massbins[:-1] + 0.5 * np.diff(massbins), indexing='ij')\n",
    "rhopts = 2*np.log(masspts/ptpts)\n",
    "ptscaled = (ptpts - 450.) / (1200. - 450.)\n",
    "rhoscaled = (rhopts - (-6)) / ((-2.1) - (-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build actual fit model now\n",
    "model = rl.Model(\"testModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ptbin in range(npt):\n",
    "    for region in ['pass']:\n",
    "        ch = rl.Channel(\"ptbin%d%s\" % (ptbin, region))\n",
    "        model.addChannel(ch)\n",
    "\n",
    "        isPass = region == 'pass'\n",
    "        ptnorm = 1.\n",
    "\n",
    "        for sName in ['HWW', 'WJetsLNu', 'TTbar']:\n",
    "            # some mock expectations\n",
    "            templ = get_template(sName, ptbin)\n",
    "            stype = rl.Sample.SIGNAL if sName == 'HWW' else rl.Sample.BACKGROUND\n",
    "            sample = rl.TemplateSample(ch.name + '_' + sName, stype, templ)\n",
    "\n",
    "            ### systematics NOT from parquets\n",
    "            for sys_name, sys_value in sys_dict.items():\n",
    "                sample.setParamEffect(sys_value, \n",
    "                                      sys_dict_values[sys_name][0], \n",
    "                                      sys_dict_values[sys_name][1] if sys_dict_values[sys_name][1] is not None else sys_dict_values[sys_name][0])\n",
    "            \n",
    "\n",
    "            ### systematics from parquets\n",
    "            # apply systematics that are common for all samples\n",
    "            for sys_name, sys_value in sys_from_parquets[\"mu\"][\"all_samples\"].items():\n",
    "                syst_up = hists_templates[\"cat1_sr\"][{\"samples\": sName, \"fj_pt\": ptbin, \"systematic\": sys_name+\"Up\"}].values()\n",
    "                syst_do = hists_templates[\"cat1_sr\"][{\"samples\": sName, \"fj_pt\": ptbin, \"systematic\": sys_name+\"Down\"}].values()\n",
    "                nominal = hists_templates[\"cat1_sr\"][{\"samples\": sName, \"fj_pt\": ptbin, \"systematic\": \"Nominal\"}].values()\n",
    "                \n",
    "                eff_up = shape_to_num(syst_up,nominal)\n",
    "                eff_do = shape_to_num(syst_do,nominal)\n",
    "                \n",
    "                sample.setParamEffect(sys_value, eff_up, eff_do)\n",
    "\n",
    "            # apply systematics that are common for this particular sample\n",
    "            for sys_name, sys_value in sys_from_parquets[\"mu\"][sName].items():\n",
    "                syst_up = hists_templates[\"cat1_sr\"][{\"samples\": sName, \"fj_pt\": ptbin, \"systematic\": sys_name+\"Up\"}].values()\n",
    "                syst_do = hists_templates[\"cat1_sr\"][{\"samples\": sName, \"fj_pt\": ptbin, \"systematic\": sys_name+\"Down\"}].values()\n",
    "                nominal = hists_templates[\"cat1_sr\"][{\"samples\": sName, \"fj_pt\": ptbin, \"systematic\": \"Nominal\"}].values()\n",
    "                \n",
    "                eff_up = shape_to_num(syst_up,nominal)\n",
    "                eff_do = shape_to_num(syst_do,nominal)\n",
    "                \n",
    "                sample.setParamEffect(sys_value, eff_up, eff_do)\n",
    "\n",
    "            ch.addSample(sample)\n",
    "        \n",
    "        # add data\n",
    "        data_obs = get_template(\"Data\", ptbin)\n",
    "        ch.setObservation(data_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdir = \"tmpdir/\"\n",
    "with open(os.path.join(str(tmpdir), 'testModel.pkl'), \"wb\") as fout:\n",
    "    pkl.dump(model, fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffea-env",
   "language": "python",
   "name": "coffea-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
