{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigger efficiency with a skimmer\n",
    "\n",
    "```\n",
    "mkdir data/\n",
    "scp -r cmslpc-sl7.fnal.gov:/eos/uscms/store/user/lpcdihiggsboost/cmantill/PFNano/2017_UL_ak15/GluGluHToWWToLNuQQ_M125_TuneCP5_PSweight_13TeV-powheg2-jhugen727-pythia8/RunIISummer19UL17Jun23-106X_mc2017_realistic_v6-v2/210623_225150/0000/nano_mc2017_1-130.root data/nano_mc2017_1-130.root\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we import some libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "from hist.intervals import clopper_pearson_interval\n",
    "\n",
    "# we suppress ROOT warnings where our input ROOT tree has duplicate branches - these are handled correctly.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Found duplicate branch \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the matching function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getParticles(genparticles,lowid=22,highid=25,flags=['fromHardProcess', 'isLastCopy']):\n",
    "    \"\"\"\n",
    "    returns the particle objects that satisfy a low id, \n",
    "    high id condition and have certain flags\n",
    "    \"\"\"\n",
    "    absid = abs(genparticles.pdgId)\n",
    "    return genparticles[\n",
    "        ((absid >= lowid) & (absid <= highid))\n",
    "        & genparticles.hasFlags(flags)\n",
    "    ]\n",
    "\n",
    "# def match_HWWlepqq(genparticles,candidatefj):\n",
    "#     \"\"\"\n",
    "#     return the number of matched objects (hWW*),daughters, \n",
    "#     and gen flavor (enuqq, munuqq, taunuqq) \n",
    "#     \"\"\"\n",
    "#     W_PDGID = 24\n",
    "#     HIGGS_PDGID = 25\n",
    "#     higgs = getParticles(genparticles,HIGGS_PDGID)\n",
    "#     is_hWW = ak.all(abs(higgs.children.pdgId)==W_PDGID,axis=2)\n",
    "\n",
    "#     higgs = higgs[is_hWW]\n",
    "#     higgs_wstar = higgs.children[ak.argmin(higgs.children.mass,axis=2,keepdims=True)]\n",
    "#     higgs_w = higgs.children[ak.argmax(higgs.children.mass,axis=2,keepdims=True)]\n",
    "    \n",
    "#     prompt_electron = getParticles(genparticles,11,11,['isPrompt','isLastCopy'])\n",
    "#     prompt_muon = getParticles(genparticles,13,13,['isPrompt', 'isLastCopy'])\n",
    "#     prompt_tau = getParticles(genparticles,15,15,['isPrompt', 'isLastCopy'])\n",
    "#     prompt_q = getParticles(genparticles,0,5,['fromHardProcess', 'isLastCopy'])\n",
    "#     prompt_q = prompt_q[abs(prompt_q.distinctParent.pdgId) == W_PDGID]\n",
    "    \n",
    "#     dr_fj_quarks = candidatefj.delta_r(prompt_q)\n",
    "#     dr_fj_electrons = candidatefj.delta_r(prompt_electron)\n",
    "#     dr_fj_muons = candidatefj.delta_r(prompt_muon)\n",
    "#     dr_fj_taus = candidatefj.delta_r(prompt_tau)\n",
    "#     dr_daughters = ak.concatenate([dr_fj_quarks,dr_fj_electrons,dr_fj_muons,dr_fj_taus],axis=1)\n",
    "#     hWWlepqq_nprongs = ak.sum(dr_daughters<0.8,axis=1)\n",
    "    \n",
    "#     n_electrons = ak.sum(prompt_electron.pt>0,axis=1)\n",
    "#     n_muons = ak.sum(prompt_muon.pt>0,axis=1)\n",
    "#     n_taus = ak.sum(prompt_tau.pt>0,axis=1)\n",
    "#     n_quarks = ak.sum(prompt_q.pt>0,axis=1)\n",
    "\n",
    "#     # 4(elenuqq),6(munuqq),8(taunuqq)\n",
    "#     hWWlepqq_flavor = (n_quarks==2)*1 + (n_electrons==1)*3 + (n_muons==1)*5 + (n_taus==1)*7\n",
    "    \n",
    "#     matchedH = candidatefj.nearest(higgs, axis=1, threshold=0.8)\n",
    "#     matchedW = candidatefj.nearest(higgs_w, axis=1, threshold=0.8)\n",
    "#     matchedWstar = candidatefj.nearest(higgs_wstar, axis=1, threshold=0.8) \n",
    "\n",
    "#     # 1 (H only), 4(W), 6(W star), 9(H, W and Wstar)\n",
    "#     hWWlepqq_matched = (\n",
    "#         (ak.sum(matchedH.pt > 0, axis=1)==1) * 1 \n",
    "#         + (ak.sum(ak.flatten(matchedW.pt > 0, axis=2), axis=1)==1) * 3 \n",
    "#         + (ak.sum(ak.flatten(matchedWstar.pt > 0, axis=2), axis=1)==1) * 5\n",
    "#     )\n",
    "    \n",
    "#     # leptons matched\n",
    "#     dr_leptons = ak.concatenate([dr_fj_electrons,dr_fj_muons], axis=1)\n",
    "#     matched_leptons = dr_leptons < 0.8\n",
    "    \n",
    "#     leptons = ak.concatenate([prompt_electron, prompt_muon], axis=1)\n",
    "#     leptons = leptons[matched_leptons]\n",
    "    \n",
    "#     # leptons coming from W or W*\n",
    "#     leptons_mass = ak.firsts(leptons.distinctParent.mass)\n",
    "#     higgs_w_mass = ak.firsts(ak.flatten(higgs_w.mass))[ak.firsts(leptons.pt > 0)]\n",
    "#     higgs_wstar_mass = ak.firsts(ak.flatten(higgs_wstar.mass))[ak.firsts(leptons.pt > 0)]\n",
    "\n",
    "#     iswlepton = (leptons_mass == higgs_w_mass)\n",
    "#     iswstarlepton = (leptons_mass == higgs_wstar_mass)\n",
    "    \n",
    "#     # let's return only:\n",
    "#     # - matchedH (the higgs boson that is matched to the jet)\n",
    "#     # - (iswlepton,iswstarlepton)\n",
    "#     return matchedH,iswlepton,iswstarlepton\n",
    "\n",
    "\n",
    "\n",
    "def match_HWW(genparticles, candidatefj):\n",
    "    \"\"\"\n",
    "    return the number of matched objects (hWW*),daughters,\n",
    "    and gen flavor (enuqq, munuqq, taunuqq)\n",
    "    \"\"\"\n",
    "    higgs = getParticles(genparticles, 25)   # genparticles is the full set... this function selects Higgs particles\n",
    "    is_hWW = ak.all(abs(higgs.children.pdgId) == 24, axis=2)    # W~24 so we get H->WW (limitation: only picking one W and assumes the other will be there)\n",
    "\n",
    "    higgs = higgs[is_hWW]\n",
    "#     higgs_wstar = higgs.children[ak.argmin(higgs.children.mass, axis=2, keepdims=True)]\n",
    "#     higgs_w = higgs.children[ak.argmax(higgs.children.mass, axis=2, keepdims=True)]\n",
    "#\n",
    "#     prompt_electron = getParticles(genparticles, 11, 11, ['isPrompt', 'isLastCopy'])    # isPrompt avoids displaced leptons\n",
    "#     prompt_muon = getParticles(genparticles, 13, 13, ['isPrompt', 'isLastCopy'])\n",
    "#     prompt_tau = getParticles(genparticles, 15, 15, ['isPrompt', 'isLastCopy'])\n",
    "#     prompt_q = getParticles(genparticles, 0, 5, ['fromHardProcess', 'isLastCopy'])      # 0-5 not 0-6 to avoid top quark\n",
    "#     prompt_q = prompt_q[abs(prompt_q.distinctParent.pdgId) == 24]       # parent W\n",
    "\n",
    "#     dr_fj_quarks = candidatefj.delta_r(prompt_q)\n",
    "#     dr_fj_electrons = candidatefj.delta_r(prompt_electron)\n",
    "#     dr_fj_muons = candidatefj.delta_r(prompt_muon)\n",
    "#     dr_fj_taus = candidatefj.delta_r(prompt_tau)\n",
    "#     dr_daughters = ak.concatenate([dr_fj_quarks, dr_fj_electrons, dr_fj_muons, dr_fj_taus], axis=1)\n",
    "#     hWW_nprongs = ak.sum(dr_daughters < 0.8, axis=1)   # impose that something must be inside the cone... tells you # of particles from Higgs matched to the jet\n",
    "\n",
    "#     n_electrons = ak.sum(prompt_electron.pt > 0, axis=1)\n",
    "#     n_muons = ak.sum(prompt_muon.pt > 0, axis=1)\n",
    "#     n_taus = ak.sum(prompt_tau.pt > 0, axis=1)\n",
    "#     n_quarks = ak.sum(prompt_q.pt > 0, axis=1)\n",
    "\n",
    "#     # 4(elenuqq),6(munuqq),8(taunuqq)\n",
    "#     hWW_flavor = (n_quarks == 2) * 1 + (n_electrons == 1) * 3 + (n_muons == 1) * 5 + (n_taus == 1) * 7 + (n_quarks == 4) * 11\n",
    "\n",
    "    matchedH = candidatefj.nearest(higgs, axis=1, threshold=0.8)    # choose higgs closest to fj\n",
    "#     matchedW = candidatefj.nearest(higgs_w, axis=1, threshold=0.8)  # choose W closest to fj\n",
    "#     matchedWstar = candidatefj.nearest(higgs_wstar, axis=1, threshold=0.8)  # choose Wstar closest to fj\n",
    "\n",
    "#     # 1 (H only), 4(W), 6(W star), 9(H, W and Wstar)\n",
    "#     hWW_matched = (\n",
    "#         (ak.sum(matchedH.pt > 0, axis=1) == 1) * 1\n",
    "#         + (ak.sum(ak.flatten(matchedW.pt > 0, axis=2), axis=1) == 1) * 3\n",
    "#         + (ak.sum(ak.flatten(matchedWstar.pt > 0, axis=2), axis=1) == 1) * 5\n",
    "#     )\n",
    "\n",
    "#     # leptons matched\n",
    "#     dr_fj_leptons = ak.concatenate([dr_fj_electrons, dr_fj_muons], axis=1)\n",
    "\n",
    "#     leptons = ak.concatenate([prompt_electron, prompt_muon], axis=1)\n",
    "#     leptons = leptons[dr_fj_leptons < 0.8]\n",
    "\n",
    "#     # leptons coming from W or W*\n",
    "#     leptons_mass = ak.firsts(leptons.distinctParent.mass)   # # TODO: why need firsts\n",
    "#     higgs_w_mass = ak.firsts(ak.flatten(higgs_w.mass))[ak.firsts(leptons.pt > 0)]\n",
    "#     higgs_wstar_mass = ak.firsts(ak.flatten(higgs_wstar.mass))[ak.firsts(leptons.pt > 0)]\n",
    "\n",
    "#     iswlepton = (leptons_mass == higgs_w_mass)\n",
    "#     iswstarlepton = (leptons_mass == higgs_wstar_mass)\n",
    "\n",
    "#     genVars = {\n",
    "#         \"hWW_flavor\": hWW_flavor,\n",
    "#         \"hWW_matched\": hWW_matched,\n",
    "#         \"hWW_nprongs\": hWW_nprongs,\n",
    "#         \"matchedH\": matchedH,\n",
    "#         \"iswlepton\": iswlepton,  # truth info, higher mass is normally onshell\n",
    "#         \"iswstarlepton\": iswstarlepton}  # truth info, lower mass is normally offshell\n",
    "    \n",
    "#     return genVars\n",
    "\n",
    "    return matchedH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define a processor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from coffea.processor import ProcessorABC, column_accumulator\n",
    "from coffea.nanoevents.methods import candidate, vector\n",
    "from coffea.analysis_tools import Weights, PackedSelection\n",
    "    \n",
    "# \"ele\": [\n",
    "#     \"Ele35_WPTight_Gsf\",\n",
    "#     \"Ele115_CaloIdVT_GsfTrkIdT\",\n",
    "#     \"Photon200\"\n",
    "# ],\n",
    "# \"mu\": [\n",
    "#     \"Mu50\",\n",
    "#     \"IsoMu27\",\n",
    "#     \"OldMu100\",\n",
    "#     \"TkMu100\"\n",
    "# ],\n",
    "    \n",
    "class TriggerEfficienciesProcessor(ProcessorABC):\n",
    "    \"\"\" Accumulates histograms from all input events: 1) before triggers, and 2) after triggers \"\"\"\n",
    "    def __init__(self, year=2017):\n",
    "        super(TriggerEfficienciesProcessor, self).__init__()\n",
    "        self._year = year\n",
    "        self._trigger_dict = {\n",
    "            2017:{\n",
    "                \"ele35\": [\n",
    "                    \"Ele35_WPTight_Gsf\",\n",
    "                ],\n",
    "                \"ele115\": [\n",
    "                    \"Ele115_CaloIdVT_GsfTrkIdT\"\n",
    "                ],\n",
    "                \"Photon200\": [\n",
    "                    \"Photon200\"\n",
    "                ],\n",
    "                \"Mu50\": [\n",
    "                    \"Mu50\",\n",
    "                ],\n",
    "                \"IsoMu27\": [\n",
    "                    \"IsoMu27\"\n",
    "                ],\n",
    "                \"OldMu100\": [\n",
    "                    \"OldMu100\"\n",
    "                ],\n",
    "               \"TkMu100\": [\n",
    "                    \"TkMu100\"\n",
    "                ],                \n",
    "            }\n",
    "        }[self._year]\n",
    "        self._triggers = {\"ele\": [\"ele35\",\"ele115\",\"Photon200\"],\n",
    "                          \"mu\": [\"Mu50\",\"IsoMu27\",\"OldMu100\",\"TkMu100\"],\n",
    "                         }\n",
    "        \n",
    "        self._channels = [\"ele\",\"mu\"]\n",
    "    \n",
    "    def pad_val(\n",
    "        self, arr: ak.Array, target: int, value: float, axis: int = 0, to_numpy: bool = True\n",
    "    ):\n",
    "        \"\"\"pads awkward array up to `target` index along axis `axis` with value `value`, optionally converts to numpy array\"\"\"\n",
    "        ret = ak.fill_none(ak.pad_none(arr, target, axis=axis, clip=True), value)\n",
    "        return ret.to_numpy() if to_numpy else ret\n",
    "    \n",
    "    def process(self, events):\n",
    "        \"\"\" Returns pre- (den) and post- (num) trigger histograms from input NanoAOD events \"\"\"\n",
    "        dataset = events.metadata['dataset']\n",
    "        n_events = len(events)\n",
    "        isRealData = not hasattr(events, \"genWeight\")\n",
    "        \n",
    "        def pad_val_nevents(arr: ak.Array):\n",
    "            \"\"\"pad values with the length equal to the number of events\"\"\"\n",
    "            return self.pad_val(arr, n_events, -1)\n",
    "    \n",
    "        # skimmed events for different channels\n",
    "        out = {}\n",
    "        for channel in self._channels:\n",
    "            out[channel] = {}\n",
    "\n",
    "        \"\"\" Save OR of triggers as booleans \"\"\"\n",
    "        for channel in self._channels:\n",
    "            HLT_triggers = {}\n",
    "            for t in self._triggers[channel]:\n",
    "                HLT_triggers[\"HLT_\"+t] = np.any(\n",
    "                        np.array(\n",
    "                            [\n",
    "                                events.HLT[trigger] for trigger in self._trigger_dict[t] if trigger in events.HLT.fields\n",
    "                            ]\n",
    "                        ),\n",
    "                        axis=0,\n",
    "                )                \n",
    "            out[channel] = {**out[channel], **HLT_triggers}\n",
    "\n",
    "        \"\"\" Baseline selection \"\"\"\n",
    "        goodmuon = (\n",
    "            (events.Muon.pt > 25)\n",
    "            & (abs(events.Muon.eta) < 2.4)\n",
    "            & events.Muon.mediumId\n",
    "        )\n",
    "        nmuons = ak.sum(goodmuon, axis=1)\n",
    "        goodelectron = (\n",
    "            (events.Electron.pt > 25)\n",
    "            & (abs(events.Electron.eta) < 2.5)\n",
    "            & (events.Electron.mvaFall17V2noIso_WP90)\n",
    "        )\n",
    "        nelectrons = ak.sum(goodelectron, axis=1)\n",
    "        \n",
    "        # taus (will need to refine to avoid overlap with htt)\n",
    "        loose_taus_mu = (events.Tau.pt > 20) & (abs(events.Tau.eta) < 2.3) & (events.Tau.idAntiMu >= 1)  # loose antiMu ID\n",
    "        loose_taus_ele = (\n",
    "            (events.Tau.pt > 20)\n",
    "            & (abs(events.Tau.eta) < 2.3)\n",
    "            & (events.Tau.idAntiEleDeadECal >= 2)  # loose Anti-electron MVA discriminator V6 (2018) ?\n",
    "        )\n",
    "        n_loose_taus_mu = ak.sum(loose_taus_mu, axis=1)\n",
    "        n_loose_taus_ele = ak.sum(loose_taus_ele, axis=1)\n",
    "\n",
    "        # leading lepton\n",
    "        goodleptons = ak.concatenate([events.Muon[goodmuon], events.Electron[goodelectron]], axis=1)\n",
    "        candidatelep = ak.firsts(goodleptons[ak.argsort(goodleptons.pt)])\n",
    "        \n",
    "        # fatjet closest to MET\n",
    "        fatjets = events.FatJet\n",
    "        candidatefj = fatjets[\n",
    "            (fatjets.pt > 200) &\n",
    "            (abs(fatjets.eta) < 2.4)\n",
    "        ]\n",
    "        met = events.MET\n",
    "        dphi_met_fj = abs(candidatefj.delta_phi(met))\n",
    "        candidatefj = ak.firsts(candidatefj[ak.argmin(dphi_met_fj,axis=1,keepdims=True)])\n",
    "        dr_lep_fj = candidatefj.delta_r(candidatelep)\n",
    "\n",
    "        # jets\n",
    "        jets = events.Jet\n",
    "        candidatejet = jets[\n",
    "            (jets.pt > 30) \n",
    "            & (abs(jets.eta) < 2.5) \n",
    "            & jets.isTight\n",
    "        ]\n",
    "        \n",
    "        # define isolation\n",
    "        mu_iso = ak.where(candidatelep.pt >= 55., candidatelep.miniPFRelIso_all, candidatelep.pfRelIso03_all)\n",
    "        ele_iso = ak.where(candidatelep.pt >= 120., candidatelep.pfRelIso03_all, candidatelep.pfRelIso03_all)\n",
    "        \n",
    "        # define selections for different channels\n",
    "        for channel in self._channels:\n",
    "            selection = PackedSelection()\n",
    "            selection.add('fjkin', candidatefj.pt > 200)\n",
    "            if channel==\"mu\":\n",
    "                selection.add('onemuon', (nmuons == 1) & (nelectrons == 0) & (n_loose_taus_mu == 0))\n",
    "                selection.add('muonkin', (candidatelep.pt > 27.) & abs(candidatelep.eta < 2.4))\n",
    "            elif channel==\"ele\":\n",
    "                selection.add('oneelectron', (nelectrons == 1) & (nmuons == 0) & (n_loose_taus_ele == 0))\n",
    "                selection.add('electronkin', (candidatelep.pt > 30.) & abs(candidatelep.eta < 2.4))\n",
    "\n",
    "            \"\"\" Define other variables to save \"\"\"\n",
    "            out[channel][\"fj_pt\"] = pad_val_nevents(candidatefj.pt)\n",
    "            out[channel][\"fj_msoftdrop\"] = pad_val_nevents(candidatefj.msoftdrop)\n",
    "            out[channel][\"lep_pt\"] = pad_val_nevents(candidatelep.pt)\n",
    "#             if channel==\"mu\":\n",
    "#                 out[channel][\"lep_isolation\"] = pad_val_nevents(mu_iso)\n",
    "#             elif channel==\"ele\":\n",
    "#                 out[channel][\"lep_isolation\"] = pad_val_nevents(ele_iso)\n",
    "#             out[channel][\"fj_lep_mass\"] = pad_val_nevents((candidatefj - candidatelep).mass)\n",
    "#             out[channel][\"fj_lep_dR\"] = pad_val_nevents(dr_lep_fj)\n",
    "#             out[channel][\"ht\"] = pad_val_nevents(ak.sum(candidatejet.pt, axis=1))\n",
    "            \n",
    "            if \"HToWW\" in dataset:\n",
    "#                 matchedH,iswlepton,iswstarlepton = match_HWWlepqq(events.GenPart,candidatefj)\n",
    "                matchedH = match_HWW(events.GenPart,candidatefj)\n",
    "                matchedH_pt = ak.firsts(matchedH.pt)\n",
    "            else:\n",
    "                matchedH_pt = ak.zeros_like(candidatefj.pt)\n",
    "#                 iswlepton = ak.ones_like(candidatefj.pt, dtype=bool)\n",
    "#                 iswstarlepton = ak.ones_like(candidatefj.pt, dtype=bool)\n",
    "            out[channel][\"higgspt\"] = pad_val_nevents(matchedH_pt)\n",
    "#             out[channel][\"iswlepton\"] = pad_val_nevents(iswlepton)\n",
    "#             out[channel][\"iswstarlepton\"] = pad_val_nevents(iswstarlepton)\n",
    "\n",
    "            # use column accumulators\n",
    "            out[channel] = {\n",
    "                key: column_accumulator(value[selection.all(*selection.names)])\n",
    "                for (key, value) in out[channel].items()\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            self._year: {\n",
    "                dataset: {\"nevents\": n_events, \"skimmed_events\": out}\n",
    "            }\n",
    "        }\n",
    "\n",
    "                  \n",
    "    def postprocess(self, accumulator):\n",
    "        for year, datasets in accumulator.items():\n",
    "            for dataset, output in datasets.items():\n",
    "                for channel in output[\"skimmed_events\"].keys():\n",
    "                    output[\"skimmed_events\"][channel] = {\n",
    "                        key: value.value for (key, value) in output[\"skimmed_events\"][channel].items()\n",
    "                    }\n",
    "                \n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.030146121978759766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 45,
       "postfix": null,
       "prefix": "Preprocessing",
       "rate": null,
       "total": 1,
       "unit": "file",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6d691e04664c3ba25dc7aa07e68cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Preprocessing:   0%|          | 0/1 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02675485610961914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 45,
       "postfix": null,
       "prefix": "Processing",
       "rate": null,
       "total": 20,
       "unit": "chunk",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7934bb7ed04443e0ba9c10cbfb75069c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/20 [00:00<?, ?chunk/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import uproot\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema, BaseSchema\n",
    "\n",
    "from coffea.processor import IterativeExecutor,Runner,DaskExecutor\n",
    "\n",
    "# define fileset\n",
    "# fileset = {\"HToWW\": [\"nano_mc2017_1-1.root\"]}    ### if you have the file locally\n",
    "fileset = {\"HToWW\": [\"data/hww_1.root\", \"data/hww_2.root\"]}    ### if you have the file locally\n",
    "\n",
    "# fileset = {\"HToWW\": [\"root://xcache/\"+ filename]}         ### if you read it through xrootd\n",
    "\n",
    "# define processor\n",
    "# here you can change \"triggers\" to have more options: e.g. nominal,jet ...\n",
    "p = TriggerEfficienciesProcessor(year=2017)\n",
    "# p = HwwProcessor(year=2017)\n",
    "\n",
    "# define iterative executor (to run locally)\n",
    "executor = IterativeExecutor(compression=1, status=True, workers=1)\n",
    "\n",
    "# define the runner (with NanoAODSchema)\n",
    "run = Runner(executor=executor,savemetrics=True,chunksize=10000,schema=NanoAODSchema)\n",
    "\n",
    "# run \n",
    "out,metrics = run(fileset,'Events',processor_instance=p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELECTRON CHANNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(out[2017]['HToWW']['skimmed_events']['ele'].keys())\n",
    "\n",
    "skimmed_events_ele = out[2017][\"HToWW\"][\"skimmed_events\"][\"ele\"]\n",
    "skimmed_events_ele.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can make histograms for higgspt, jetpt, leptonpt\n",
    "import hist as hist2\n",
    "region_cat = hist2.axis.StrCategory([\"numerator\",\"denominator\"], name=\"region\")\n",
    "channel_cat = hist2.axis.StrCategory([], name='channel', growth=True)\n",
    "trigger_cat = hist2.axis.StrCategory([], name='trigger', growth=True)\n",
    "\n",
    "hpt_axis = hist2.axis.Regular(25, 100, 700, name='higgspt', label=r'matched H $p_T$ [GeV]')\n",
    "leppt_axis = hist2.axis.Regular(25, 10, 700, name='leppt', label=r'Lepton $p_T$ [GeV]')\n",
    "\n",
    "hists = hist2.Hist(\n",
    "                channel_cat,\n",
    "                region_cat,\n",
    "                trigger_cat,\n",
    "                hpt_axis,\n",
    "                leppt_axis,\n",
    "            )\n",
    "# now we can fill the histogram with the denominator (baseline selection already applied)\n",
    "higgspt = skimmed_events_ele[\"higgspt\"]\n",
    "leppt = skimmed_events_ele[\"lep_pt\"]\n",
    "\n",
    "hists.fill(\n",
    "    channel=\"ele\",\n",
    "    region=\"denominator\",\n",
    "    trigger=\"all\",\n",
    "    higgspt=higgspt,\n",
    "    leppt=leppt,\n",
    ")\n",
    "hists.fill(\n",
    "    channel=\"ele\",\n",
    "    region=\"numerator\",\n",
    "    trigger=\"ele35\",\n",
    "    higgspt=higgspt[skimmed_events_ele[\"HLT_ele35\"]],\n",
    "    leppt=leppt[skimmed_events_ele[\"HLT_ele35\"]],\n",
    "\n",
    ")\n",
    "hists.fill(\n",
    "    channel=\"ele\",\n",
    "    region=\"numerator\",\n",
    "    trigger=\"ele115\",\n",
    "    higgspt=higgspt[skimmed_events_ele[\"HLT_ele115\"]],\n",
    "    leppt=leppt[skimmed_events_ele[\"HLT_ele115\"]], \n",
    ")\n",
    "\n",
    "hists.fill(\n",
    "    channel=\"ele\",\n",
    "    region=\"numerator\",\n",
    "    trigger=\"Photon200\",\n",
    "    higgspt=higgspt[skimmed_events_ele[\"HLT_Photon200\"]],\n",
    "    leppt=leppt[skimmed_events_ele[\"HLT_Photon200\"]],   \n",
    ")\n",
    "\n",
    "hists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# now we plot trigger efficiency as function of jetpt\n",
    "num_35 = hists[{\"region\":\"numerator\", \"channel\":\"ele\", \"trigger\":\"ele35\", 'higgspt':sum}]\n",
    "num_115 = hists[{\"region\":\"numerator\", \"channel\":\"ele\", \"trigger\":\"ele115\", 'higgspt':sum}]\n",
    "num_photon = hists[{\"region\":\"numerator\", \"channel\":\"ele\", \"trigger\":\"Photon200\", 'higgspt':sum}]\n",
    "\n",
    "den = hists[{\"region\":\"denominator\", \"channel\":\"ele\", \"trigger\":sum, 'higgspt':sum}]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "from hist.intervals import clopper_pearson_interval\n",
    "def get_yerr(num,den):\n",
    "    return abs(clopper_pearson_interval(num.view(), den.view()) - num.view()/den.view())\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "hep.histplot(num_35/den, \n",
    "             ax = ax,\n",
    "             color='red', \n",
    "             label=\"ele35\",\n",
    "#              histtype='errorbar', \n",
    "#              yerr=get_yerr(num_35, den),\n",
    "#              capsize=4, \n",
    "#              elinewidth=1,              \n",
    ")\n",
    "hep.histplot(num_115/den, \n",
    "             ax = ax,\n",
    "             color='blue', \n",
    "             label=\"ele115\",             \n",
    "#              histtype='errorbar', \n",
    "#              yerr=get_yerr(num_35, den),\n",
    "#              capsize=4,  \n",
    "#              elinewidth=1, \n",
    ")\n",
    "hep.histplot(num_photon/den, \n",
    "             ax = ax,\n",
    "             color='green', \n",
    "             label=\"Photon200\",\n",
    "#              histtype='errorbar', \n",
    "#              yerr=get_yerr(num_35, den),    \n",
    "#              capsize=4,   \n",
    "#              elinewidth=1,              \n",
    ")\n",
    "ax.set_ylim(0,1)\n",
    "ax.legend()\n",
    "plt.savefig(f'trigger_efficiecny_plots/leppt_ele.pdf');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we plot trigger efficiency as function of jetpt\n",
    "num_35 = hists[{\"region\":\"numerator\", \"channel\":\"ele\", \"trigger\":\"ele35\", 'leppt':sum}]\n",
    "num_115 = hists[{\"region\":\"numerator\", \"channel\":\"ele\", \"trigger\":\"ele115\", 'leppt':sum}]\n",
    "num_photon = hists[{\"region\":\"numerator\", \"channel\":\"ele\", \"trigger\":\"Photon200\", 'leppt':sum}]\n",
    "\n",
    "den = hists[{\"region\":\"denominator\", \"channel\":\"ele\", \"trigger\":sum, 'leppt':sum}]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "from hist.intervals import clopper_pearson_interval\n",
    "def get_yerr(num,den):\n",
    "    return abs(clopper_pearson_interval(num.view(), den.view()) - num.view()/den.view())\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "hep.histplot(num_35/den, \n",
    "             ax = ax,\n",
    "             color='red', \n",
    "             label=\"ele35\",\n",
    "#              histtype='errorbar', \n",
    "#              yerr=get_yerr(num_35, den),\n",
    "#              capsize=4, \n",
    "#              elinewidth=1,              \n",
    ")\n",
    "hep.histplot(num_115/den, \n",
    "             ax = ax,\n",
    "             color='blue', \n",
    "             label=\"ele115\",             \n",
    "#              histtype='errorbar', \n",
    "#              yerr=get_yerr(num_35, den),\n",
    "#              capsize=4,  \n",
    "#              elinewidth=1, \n",
    ")\n",
    "hep.histplot(num_photon/den, \n",
    "             ax = ax,\n",
    "             color='green', \n",
    "             label=\"Photon200\",\n",
    "#              histtype='errorbar', \n",
    "#              yerr=get_yerr(num_35, den),    \n",
    "#              capsize=4,   \n",
    "#              elinewidth=1,              \n",
    ")\n",
    "ax.set_ylim(0,1)\n",
    "ax.legend()\n",
    "plt.savefig(f'trigger_efficiecny_plots/higgspt_ele.pdf');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
