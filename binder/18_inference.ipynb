{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging inference \n",
    "\n",
    "Using latest version of coffea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cmantill/miniconda3/envs/hww/lib/python3.7/site-packages/numba/core/cpu.py:77: UserWarning: Numba extension module 'awkward1._connect._numba' failed to load due to 'ImportError(generic_type: type \"kernel_lib\" is already registered!)'.\n",
      "  numba.core.entrypoints.init_all()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import pickle as pkl\n",
    "import pyarrow as pa\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "from typing import List, Optional, Dict\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import importlib.resources\n",
    "\n",
    "from coffea import processor\n",
    "from coffea.nanoevents.methods import candidate, vector\n",
    "from coffea.analysis_tools import Weights, PackedSelection\n",
    "\n",
    "from coffea.nanoevents.methods.base import NanoEventsArray\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema, PFNanoAODSchema\n",
    "from coffea.nanoevents.methods import candidate, vector\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Found duplicate branch \")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"Missing cross-reference index \")\n",
    "np.seterr(invalid='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NanoAODschema\n",
    "\n",
    "We want to use PFNanoAODSchema since that load PFCands as a candidate particles, i.e. they have 4-vector properties.\n",
    "\n",
    "https://coffeateam.github.io/coffea/api/coffea.nanoevents.PFNanoAODSchema.html\n",
    "https://github.com/CoffeaTeam/coffea/blob/7dd4f863837a6319579f078c9e445c61d9106943/coffea/nanoevents/schemas/nanoaod.py#L282\n",
    "\n",
    "Additionally, PFNanoAODSchema loads SecondaryVertices as SecondaryVertex:\n",
    "https://github.com/CoffeaTeam/coffea/blob/7dd4f863837a6319579f078c9e445c61d9106943/coffea/nanoevents/schemas/nanoaod.py#L68\n",
    "https://github.com/CoffeaTeam/coffea/blob/f2a99631dcf95b46bd0225b242b3ba512a30a89a/coffea/nanoevents/methods/nanoaod.py#L388\n",
    "\n",
    "We do not neccessarily want this since this means we don't have a candidate 4-vector for the SecondaryVertex and we can't do operations like `delta_phi`. \n",
    "We need to modify this to a `mixin` of PFCand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PFCand\n",
      "SecondaryVertex\n",
      "PFCand\n"
     ]
    }
   ],
   "source": [
    "print(PFNanoAODSchema.mixins['PFCands'])\n",
    "print(PFNanoAODSchema.mixins['SV'])\n",
    "\n",
    "# interpret SV with PFCand behavior\n",
    "PFNanoAODSchema.mixins[\"SV\"] = \"PFCand\"\n",
    "\n",
    "print(PFNanoAODSchema.mixins['SV'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening file w PFNanoAODSchema\n",
    "\n",
    "Here we manually open the file (only 200 entries), and we use `PFNanoAODSchema`.\n",
    "We also open the json file that specifies how many pf candidates/svs are going to be used in the tagger, as well as any normalization that should be applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'dy_sample.root'\n",
    "events = NanoEventsFactory.from_root(file, schemaclass=PFNanoAODSchema, entry_stop=200).events()\n",
    "\n",
    "with open(f\"03_31_ak8.json\") as f:\n",
    "    tagger_vars = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the selection such that it mimics the boostedHiggs selection. We use the fatjet closest to the lepton and obtain its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_p4(cand):\n",
    "    return ak.zip(\n",
    "        {\n",
    "            \"pt\": cand.pt,\n",
    "            \"eta\": cand.eta,\n",
    "            \"phi\": cand.phi,\n",
    "            \"mass\": cand.mass,\n",
    "            \"charge\": cand.charge,\n",
    "        },\n",
    "        with_name=\"PtEtaPhiMCandidate\",\n",
    "        behavior=candidate.behavior,\n",
    "    )\n",
    "\n",
    "good_muons = (\n",
    "    (events.Muon.pt > 30)\n",
    "    & (np.abs(events.Muon.eta) < 2.4)\n",
    "    & (np.abs(events.Muon.dz) < 0.1)\n",
    "    & (np.abs(events.Muon.dxy) < 0.05)\n",
    "    & (events.Muon.sip3d <= 4.0)\n",
    "    & events.Muon.mediumId\n",
    ")   \n",
    "good_electrons = (\n",
    "    (events.Electron.pt > 38)\n",
    "    & (np.abs(events.Electron.eta) < 2.4)\n",
    "    & ((np.abs(events.Electron.eta) < 1.44) | (np.abs(events.Electron.eta) > 1.57))\n",
    "    & (np.abs(events.Electron.dz) < 0.1)\n",
    "    & (np.abs(events.Electron.dxy) < 0.05)\n",
    "    & (events.Electron.sip3d <= 4.0)\n",
    "    & (events.Electron.mvaFall17V2noIso_WP90)\n",
    ")\n",
    "\n",
    "# get candidate lepton\n",
    "goodleptons = ak.concatenate([events.Muon[good_muons], events.Electron[good_electrons]], axis=1)    # concat muons and electrons\n",
    "goodleptons = goodleptons[ak.argsort(goodleptons.pt, ascending=False)]      # sort by pt\n",
    "candidatelep = ak.firsts(goodleptons)   # pick highest pt\n",
    "candidatelep_p4 = build_p4(candidatelep) \n",
    "\n",
    "# get candidate fj\n",
    "fatjets = events.FatJet\n",
    "good_fatjets = (\n",
    "    (fatjets.pt > 200)\n",
    "    & (abs(fatjets.eta) < 2.5)\n",
    "    & fatjets.isTight\n",
    ")\n",
    "n_fatjets = ak.sum(good_fatjets, axis=1)\n",
    "good_fatjets = fatjets[good_fatjets]        # select good fatjets\n",
    "good_fatjets = good_fatjets[ak.argsort(good_fatjets.pt, ascending=False)]    # sort by pt\n",
    "lep_in_fj_overlap_bool = ~ak.is_none(ak.firsts(good_fatjets.delta_r(candidatelep_p4) > 0.1))\n",
    "good_fatjets = ak.mask(good_fatjets, lep_in_fj_overlap_bool)\n",
    "\n",
    "# get idx and fj\n",
    "fj_idx_lep = ak.argmin(good_fatjets.delta_r(candidatelep_p4), axis=1, keepdims=True)\n",
    "candidatefj_lep = ak.firsts(good_fatjets[fj_idx_lep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices where jet pt > 0\n",
      "(array([ 17,  48,  66,  74,  80,  81,  82,  90,  92, 104, 105, 116, 123,\n",
      "       159, 160, 164]),)\n"
     ]
    }
   ],
   "source": [
    "fatjet_label = \"FatJet\"\n",
    "pfcands_label = \"FatJetPFCands\"\n",
    "svs_label = \"FatJetSVs\"\n",
    "\n",
    "# get the jet given the index (take firsts to avoid singletons)\n",
    "jet = ak.firsts(events[fatjet_label][fj_idx_lep])\n",
    "\n",
    "# print indices of events where we actually have a jet\n",
    "print('Indices where jet pt > 0')\n",
    "print(np.where((ak.fill_none(jet.pt,-1)>0).to_numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug PFCand features and mask\n",
    "\n",
    "The mask is just an array with a subarray of the lenght of the number of features e.g. (100). \n",
    "\n",
    "For example, if for a given jet we only have 2 PF Candidates and we have 100 PFcandidate points in our network, we would have:\n",
    "```\n",
    "mask = [1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
    " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
    " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
    " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
    " 0. 0. 0. 0.]\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "See how pfcand variable looks for jet 48\n",
      "[1.26, 1.46, 1.45, 1.41, 1.34, 1.28, 1.44, 1.06]\n",
      "Pad until sub-arrays have the same length\n",
      "[[-- -- -- ... -- -- --]\n",
      " [-- -- -- ... -- -- --]\n",
      " [-- -- -- ... -- -- --]\n",
      " ...\n",
      " [-- -- -- ... -- -- --]\n",
      " [-- -- -- ... -- -- --]\n",
      " [-- -- -- ... -- -- --]]\n",
      "Invert the mask\n",
      "[[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "Convert mask to ones\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "See how mask looks for jet 48\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "jet = ak.firsts(events[fatjet_label][fj_idx_lep])\n",
    "msk = events[pfcands_label].jetIdx == ak.firsts(fj_idx_lep)\n",
    "jet_ak_pfcands = events[pfcands_label][msk]\n",
    "jet_pfcands = (events.PFCands[jet_ak_pfcands.pFCandsIdx])\n",
    "\n",
    "# get any feature of pfcands\n",
    "pfcand_abseta = np.abs(jet_pfcands.eta)\n",
    "\n",
    "# index for jet w pfcands \n",
    "test_idx = 48\n",
    "\n",
    "print(f'See how pfcand variable looks for jet {test_idx}')\n",
    "print(pfcand_abseta[test_idx])\n",
    "print('Pad until sub-arrays have the same length')\n",
    "print(ak.pad_none(pfcand_abseta, tagger_vars[\"pf_points\"][\"var_length\"], axis=1, clip=True).to_numpy())\n",
    "# print('Get a mask')\n",
    "# print(ak.pad_none(pfcand_abseta, tagger_vars[\"pf_points\"][\"var_length\"], axis=1, clip=True).to_numpy().mask)\n",
    "print('Invert the mask')\n",
    "print(~(ak.pad_none(pfcand_abseta, tagger_vars[\"pf_points\"][\"var_length\"], axis=1, clip=True).to_numpy().mask))\n",
    "print('Convert mask to ones')\n",
    "print((~(ak.pad_none(pfcand_abseta, tagger_vars[\"pf_points\"][\"var_length\"], axis=1, clip=True).to_numpy().mask)).astype(np.float32))\n",
    "pfcand_mask = (~(ak.pad_none(pfcand_abseta, tagger_vars[\"pf_points\"][\"var_length\"], axis=1, clip=True).to_numpy().mask)).astype(np.float32)\n",
    "print(f'See how mask looks for jet {test_idx}')\n",
    "print(pfcand_mask[test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Debug SV features and mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  0 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "  0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1\n",
      " -1 -1  0 -1 -1 -1 -1 -1  1  0  0 -1 -1 -1 -1 -1 -1 -1  0 -1  0 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1  2  0 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  0 -1 -1 -1\n",
      " -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  2  0 -1 -1 -1  1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "Index of events where we actually have SVs\n",
      "(array([ 66,  80, 104, 123, 159, 164]),)\n",
      "See how sv variable looks for jet 66\n",
      "[0.0429]\n",
      "Convert mask to ones and zeros\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "See how mask looks for jet 66\n",
      "[1. 0. 0. 0. 0. 0. 0.]\n",
      "Delta phi for jet 66\n",
      "[0.0332]\n",
      "Fields for jet svs\n",
      "['charge', 'chi2', 'dlen', 'dlenSig', 'dxy', 'dxySig', 'eta', 'mass', 'ndof', 'ntracks', 'pAngle', 'phi', 'pt', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "jet = ak.firsts(events[fatjet_label][fj_idx_lep])\n",
    "msk = (events[svs_label].jetIdx == ak.firsts(fj_idx_lep))\n",
    "\n",
    "# find index where msk is true and svIdx is not -1\n",
    "sv_msk = (events[svs_label].sVIdx != -1) * (msk)\n",
    "count_sv = ak.fill_none(ak.sum(sv_msk,axis=1),-1,axis=0).to_numpy()\n",
    "print(count_sv)\n",
    "print('Index of events where we actually have SVs')\n",
    "print(np.where(count_sv>0))\n",
    "\n",
    "# get jet svs\n",
    "jet_svs = events.SV[\n",
    "        events[svs_label].sVIdx[sv_msk]\n",
    "        ]\n",
    "\n",
    "# index for jet w svs\n",
    "test_idx = 66\n",
    "\n",
    "# get sv  feature\n",
    "eta_sign = ak.values_astype(jet_svs.eta > 0, int) * 2 - 1\n",
    "sv_etarel = eta_sign * (jet_svs.eta - jet.eta)\n",
    "print(f'See how sv variable looks for jet {test_idx}')\n",
    "print(sv_etarel[test_idx])\n",
    "\n",
    "# get mask\n",
    "sv_mask = (~(\n",
    "        ak.pad_none(\n",
    "            sv_etarel, tagger_vars[\"sv_points\"][\"var_length\"], axis=1, clip=True\n",
    "        ).to_numpy().mask)\n",
    "          ).astype(np.float32)\n",
    "print('Convert mask to ones and zeros')\n",
    "print(sv_mask)\n",
    "print(f'See how mask looks for jet {test_idx}')\n",
    "print(sv_mask[test_idx])\n",
    "print(f'Delta phi for jet {test_idx}')\n",
    "print(jet_svs.delta_phi(jet)[test_idx])\n",
    "print('Fields for jet svs')\n",
    "print(jet_svs.fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now get feature functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pfcands_features(\n",
    "    tagger_vars: dict,\n",
    "    preselected_events: NanoEventsArray,\n",
    "    fj_idx_lep,\n",
    "    fatjet_label: str = \"FatJetAK15\",\n",
    "    pfcands_label: str = \"FatJetPFCands\",\n",
    "    normalize: bool = True,\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extracts the pf_candidate features specified in the ``tagger_vars`` dict from the\n",
    "    ``preselected_events`` and returns them as a dict of numpy arrays\n",
    "    \"\"\"\n",
    "\n",
    "    feature_dict = {}\n",
    "\n",
    "    jet = ak.firsts(preselected_events[fatjet_label][fj_idx_lep])\n",
    "\n",
    "    msk = preselected_events[pfcands_label].jetIdx == ak.firsts(fj_idx_lep)\n",
    "    jet_ak_pfcands = preselected_events[pfcands_label][msk]\n",
    "    jet_pfcands = (preselected_events.PFCands[jet_ak_pfcands.pFCandsIdx])\n",
    "\n",
    "    # negative eta jets have -1 sign, positive eta jets have +1\n",
    "    eta_sign = ak.values_astype(jet_pfcands.eta > 0, int) * 2 - 1\n",
    "    feature_dict[\"pfcand_etarel\"] = eta_sign * (jet_pfcands.eta - jet.eta)\n",
    "    feature_dict[\"pfcand_phirel\"] = jet.delta_phi(jet_pfcands)\n",
    "    feature_dict[\"pfcand_abseta\"] = np.abs(jet_pfcands.eta)\n",
    "\n",
    "    feature_dict[\"pfcand_pt_log_nopuppi\"] = np.log(jet_pfcands.pt)\n",
    "    feature_dict[\"pfcand_e_log_nopuppi\"] = np.log(jet_pfcands.energy)\n",
    "\n",
    "    pdgIds = jet_pfcands.pdgId\n",
    "    feature_dict[\"pfcand_isEl\"] = np.abs(pdgIds) == 11\n",
    "    feature_dict[\"pfcand_isMu\"] = np.abs(pdgIds) == 13\n",
    "    feature_dict[\"pfcand_isChargedHad\"] = np.abs(pdgIds) == 211\n",
    "    feature_dict[\"pfcand_isGamma\"] = np.abs(pdgIds) == 22\n",
    "    feature_dict[\"pfcand_isNeutralHad\"] = np.abs(pdgIds) == 130\n",
    "\n",
    "    feature_dict[\"pfcand_charge\"] = jet_pfcands.charge\n",
    "    feature_dict[\"pfcand_VTX_ass\"] = jet_pfcands.pvAssocQuality\n",
    "    feature_dict[\"pfcand_lostInnerHits\"] = jet_pfcands.lostInnerHits\n",
    "    feature_dict[\"pfcand_quality\"] = jet_pfcands.trkQuality\n",
    "\n",
    "    feature_dict[\"pfcand_normchi2\"] = np.floor(jet_pfcands.trkChi2)\n",
    "\n",
    "    feature_dict[\"pfcand_dz\"] = jet_pfcands.dz\n",
    "    feature_dict[\"pfcand_dxy\"] = jet_pfcands.d0\n",
    "    feature_dict[\"pfcand_dzsig\"] = jet_pfcands.dz / jet_pfcands.dzErr\n",
    "    feature_dict[\"pfcand_dxysig\"] = jet_pfcands.d0 / jet_pfcands.d0Err\n",
    "\n",
    "    # btag vars\n",
    "    for var in tagger_vars[\"pf_features\"][\"var_names\"]:\n",
    "        if \"btag\" in var:\n",
    "            feature_dict[var] = jet_ak_pfcands[var[len(\"pfcand_\"):]]\n",
    "\n",
    "    # pfcand mask\n",
    "    feature_dict[\"pfcand_mask\"] = (~(ak.pad_none(feature_dict[\"pfcand_abseta\"], tagger_vars[\"pf_points\"][\"var_length\"], axis=1, clip=True).to_numpy().mask)).astype(np.float32)\n",
    "\n",
    "    # convert to numpy arrays and normalize features\n",
    "    for var in tagger_vars[\"pf_features\"][\"var_names\"]:\n",
    "        a = (\n",
    "            ak.pad_none(\n",
    "                feature_dict[var], tagger_vars[\"pf_points\"][\"var_length\"], axis=1, clip=True\n",
    "            )\n",
    "            .to_numpy()\n",
    "            .filled(fill_value=0)\n",
    "        ).astype(np.float32)\n",
    "\n",
    "        if normalize:\n",
    "            info = tagger_vars[\"pf_features\"][\"var_infos\"][var]\n",
    "            a = (a - info[\"median\"]) * info[\"norm_factor\"]\n",
    "            a = np.clip(a, info.get(\"lower_bound\", -5), info.get(\"upper_bound\", 5))\n",
    "\n",
    "        feature_dict[var] = a\n",
    "\n",
    "    if normalize:\n",
    "        var = \"pfcand_normchi2\"\n",
    "        info = tagger_vars[\"pf_features\"][\"var_infos\"][var]\n",
    "        # finding what -1 transforms to\n",
    "        chi2_min = -1 - info[\"median\"] * info[\"norm_factor\"]\n",
    "        feature_dict[var][feature_dict[var] == chi2_min] = info[\"upper_bound\"]\n",
    "    return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_svs_features(\n",
    "    tagger_vars: dict,\n",
    "    preselected_events: NanoEventsArray,\n",
    "    fj_idx_lep,\n",
    "    fatjet_label: str = \"FatJetAK15\",\n",
    "    svs_label: str = \"JetSVsAK15\",\n",
    "    normalize: bool = True,\n",
    ") -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extracts the sv features specified in the ``tagger_vars`` dict from the\n",
    "    ``preselected_events`` and returns them as a dict of numpy arrays\n",
    "    \"\"\"\n",
    "\n",
    "    feature_dict = {}\n",
    "\n",
    "    jet = ak.firsts(preselected_events[fatjet_label][fj_idx_lep])\n",
    "    msk = preselected_events[svs_label].jetIdx == ak.firsts(fj_idx_lep)\n",
    "    jet_svs = preselected_events.SV[\n",
    "        preselected_events[svs_label].sVIdx[\n",
    "            (preselected_events[svs_label].sVIdx != -1)\n",
    "            * (msk)\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # negative eta jets have -1 sign, positive eta jets have +1\n",
    "    eta_sign = ak.values_astype(jet_svs.eta > 0, int) * 2 - 1\n",
    "    feature_dict[\"sv_etarel\"] = eta_sign * (jet_svs.eta - jet.eta)\n",
    "    feature_dict[\"sv_phirel\"] = jet_svs.delta_phi(jet)\n",
    "    feature_dict[\"sv_abseta\"] = np.abs(jet_svs.eta)\n",
    "    feature_dict[\"sv_mass\"] = jet_svs.mass\n",
    "    feature_dict[\"sv_pt_log\"] = np.log(jet_svs.pt)\n",
    "\n",
    "    feature_dict[\"sv_ntracks\"] = jet_svs.ntracks\n",
    "    feature_dict[\"sv_normchi2\"] = jet_svs.chi2\n",
    "    feature_dict[\"sv_dxy\"] = jet_svs.dxy\n",
    "    feature_dict[\"sv_dxysig\"] = jet_svs.dxySig\n",
    "    feature_dict[\"sv_d3d\"] = jet_svs.dlen\n",
    "    feature_dict[\"sv_d3dsig\"] = jet_svs.dlenSig\n",
    "    svpAngle = jet_svs.pAngle\n",
    "    feature_dict[\"sv_costhetasvpv\"] = -np.cos(svpAngle)\n",
    "\n",
    "    feature_dict[\"sv_mask\"] = (~(ak.pad_none(feature_dict[\"sv_etarel\"], tagger_vars[\"sv_points\"][\"var_length\"], axis=1, clip=True).to_numpy().mask)).astype(np.float32)\n",
    "\n",
    "    # convert to numpy arrays and normalize features\n",
    "    for var in tagger_vars[\"sv_features\"][\"var_names\"]:\n",
    "        a = (\n",
    "            ak.pad_none(\n",
    "                feature_dict[var], tagger_vars[\"sv_points\"][\"var_length\"], axis=1, clip=True\n",
    "            )\n",
    "            .to_numpy()\n",
    "            .filled(fill_value=0)\n",
    "        ).astype(np.float32)\n",
    "\n",
    "        if normalize:\n",
    "            info = tagger_vars[\"sv_features\"][\"var_infos\"][var]\n",
    "            a = (a - info[\"median\"]) * info[\"norm_factor\"]\n",
    "            a = np.clip(a, info.get(\"lower_bound\", -5), info.get(\"upper_bound\", 5))\n",
    "\n",
    "        feature_dict[var] = a\n",
    "\n",
    "    return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fatjet_label = \"FatJet\"\n",
    "pfcands_label = \"FatJetPFCands\"\n",
    "svs_label = \"FatJetSVs\"\n",
    "\n",
    "selection = candidatefj_lep.pt > 200\n",
    "\n",
    "feature_dict = get_pfcands_features(tagger_vars, events[selection], fj_idx_lep[selection], fatjet_label, pfcands_label)\n",
    "feature_dict = {\n",
    "    **get_pfcands_features(tagger_vars, events[selection], fj_idx_lep[selection], fatjet_label, pfcands_label),\n",
    "    **get_svs_features(tagger_vars, events[selection], fj_idx_lep[selection], fatjet_label, svs_label)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pfcand_etarel': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'pfcand_phirel': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'pfcand_abseta': array([[-0.96000004, -0.96000004, -0.96000004, ..., -0.96000004,\n",
      "        -0.96000004, -0.96000004],\n",
      "       [-0.96000004, -0.96000004, -0.96000004, ..., -0.96000004,\n",
      "        -0.96000004, -0.96000004],\n",
      "       [-0.96000004, -0.96000004, -0.96000004, ..., -0.96000004,\n",
      "        -0.96000004, -0.96000004],\n",
      "       ...,\n",
      "       [-0.96000004, -0.96000004, -0.96000004, ..., -0.96000004,\n",
      "        -0.96000004, -0.96000004],\n",
      "       [-0.96000004, -0.96000004, -0.96000004, ..., -0.96000004,\n",
      "        -0.96000004, -0.96000004],\n",
      "       [-0.96000004, -0.96000004, -0.96000004, ..., -0.96000004,\n",
      "        -0.96000004, -0.96000004]], dtype=float32), 'pfcand_pt_log_nopuppi': array([[-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
      "       [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
      "       [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
      "       ...,\n",
      "       [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
      "       [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5],\n",
      "       [-0.5, -0.5, -0.5, ..., -0.5, -0.5, -0.5]], dtype=float32), 'pfcand_e_log_nopuppi': array([[-0.65, -0.65, -0.65, ..., -0.65, -0.65, -0.65],\n",
      "       [-0.65, -0.65, -0.65, ..., -0.65, -0.65, -0.65],\n",
      "       [-0.65, -0.65, -0.65, ..., -0.65, -0.65, -0.65],\n",
      "       ...,\n",
      "       [-0.65, -0.65, -0.65, ..., -0.65, -0.65, -0.65],\n",
      "       [-0.65, -0.65, -0.65, ..., -0.65, -0.65, -0.65],\n",
      "       [-0.65, -0.65, -0.65, ..., -0.65, -0.65, -0.65]], dtype=float32), 'pfcand_isEl': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'pfcand_isMu': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'pfcand_isChargedHad': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'pfcand_isGamma': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'pfcand_isNeutralHad': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'pfcand_charge': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'pfcand_VTX_ass': array([[-1.2, -1.2, -1.2, ..., -1.2, -1.2, -1.2],\n",
      "       [-1.2, -1.2, -1.2, ..., -1.2, -1.2, -1.2],\n",
      "       [-1.2, -1.2, -1.2, ..., -1.2, -1.2, -1.2],\n",
      "       ...,\n",
      "       [-1.2, -1.2, -1.2, ..., -1.2, -1.2, -1.2],\n",
      "       [-1.2, -1.2, -1.2, ..., -1.2, -1.2, -1.2],\n",
      "       [-1.2, -1.2, -1.2, ..., -1.2, -1.2, -1.2]], dtype=float32), 'pfcand_lostInnerHits': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'pfcand_quality': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'pfcand_normchi2': array([[-1., -1., -1., ..., -1., -1., -1.],\n",
      "       [-1., -1., -1., ..., -1., -1., -1.],\n",
      "       [-1., -1., -1., ..., -1., -1., -1.],\n",
      "       ...,\n",
      "       [-1., -1., -1., ..., -1., -1., -1.],\n",
      "       [-1., -1., -1., ..., -1., -1., -1.],\n",
      "       [-1., -1., -1., ..., -1., -1., -1.]], dtype=float32), 'pfcand_dz': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'pfcand_dxy': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'pfcand_dzsig': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'pfcand_dxysig': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'pfcand_mask': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'sv_etarel': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'sv_phirel': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32), 'sv_abseta': array([[-0.8, -0.8, -0.8, ..., -0.8, -0.8, -0.8],\n",
      "       [-0.8, -0.8, -0.8, ..., -0.8, -0.8, -0.8],\n",
      "       [-0.8, -0.8, -0.8, ..., -0.8, -0.8, -0.8],\n",
      "       ...,\n",
      "       [-0.8, -0.8, -0.8, ..., -0.8, -0.8, -0.8],\n",
      "       [-0.8, -0.8, -0.8, ..., -0.8, -0.8, -0.8],\n",
      "       [-0.8, -0.8, -0.8, ..., -0.8, -0.8, -0.8]], dtype=float32), 'sv_mass': array([[-0.36, -0.36, -0.36, ..., -0.36, -0.36, -0.36],\n",
      "       [-0.36, -0.36, -0.36, ..., -0.36, -0.36, -0.36],\n",
      "       [-0.36, -0.36, -0.36, ..., -0.36, -0.36, -0.36],\n",
      "       ...,\n",
      "       [-0.36, -0.36, -0.36, ..., -0.36, -0.36, -0.36],\n",
      "       [-0.36, -0.36, -0.36, ..., -0.36, -0.36, -0.36],\n",
      "       [-0.36, -0.36, -0.36, ..., -0.36, -0.36, -0.36]], dtype=float32), 'sv_pt_log': array([[-2.4, -2.4, -2.4, ..., -2.4, -2.4, -2.4],\n",
      "       [-2.4, -2.4, -2.4, ..., -2.4, -2.4, -2.4],\n",
      "       [-2.4, -2.4, -2.4, ..., -2.4, -2.4, -2.4],\n",
      "       ...,\n",
      "       [-2.4, -2.4, -2.4, ..., -2.4, -2.4, -2.4],\n",
      "       [-2.4, -2.4, -2.4, ..., -2.4, -2.4, -2.4],\n",
      "       [-2.4, -2.4, -2.4, ..., -2.4, -2.4, -2.4]], dtype=float32), 'sv_ntracks': array([[-3., -3., -3., ..., -3., -3., -3.],\n",
      "       [-3., -3., -3., ..., -3., -3., -3.],\n",
      "       [-3., -3., -3., ..., -3., -3., -3.],\n",
      "       ...,\n",
      "       [-3., -3., -3., ..., -3., -3., -3.],\n",
      "       [-3., -3., -3., ..., -3., -3., -3.],\n",
      "       [-3., -3., -3., ..., -3., -3., -3.]], dtype=float32), 'sv_normchi2': array([[-0.90000004, -0.90000004, -0.90000004, ..., -0.90000004,\n",
      "        -0.90000004, -0.90000004],\n",
      "       [-0.90000004, -0.90000004, -0.90000004, ..., -0.90000004,\n",
      "        -0.90000004, -0.90000004],\n",
      "       [-0.90000004, -0.90000004, -0.90000004, ..., -0.90000004,\n",
      "        -0.90000004, -0.90000004],\n",
      "       ...,\n",
      "       [-0.90000004, -0.90000004, -0.90000004, ..., -0.90000004,\n",
      "        -0.90000004, -0.90000004],\n",
      "       [-0.90000004, -0.90000004, -0.90000004, ..., -0.90000004,\n",
      "        -0.90000004, -0.90000004],\n",
      "       [-0.90000004, -0.90000004, -0.90000004, ..., -0.90000004,\n",
      "        -0.90000004, -0.90000004]], dtype=float32), 'sv_dxy': array([[-0.1, -0.1, -0.1, ..., -0.1, -0.1, -0.1],\n",
      "       [-0.1, -0.1, -0.1, ..., -0.1, -0.1, -0.1],\n",
      "       [-0.1, -0.1, -0.1, ..., -0.1, -0.1, -0.1],\n",
      "       ...,\n",
      "       [-0.1, -0.1, -0.1, ..., -0.1, -0.1, -0.1],\n",
      "       [-0.1, -0.1, -0.1, ..., -0.1, -0.1, -0.1],\n",
      "       [-0.1, -0.1, -0.1, ..., -0.1, -0.1, -0.1]], dtype=float32), 'sv_dxysig': array([[-0.14, -0.14, -0.14, ..., -0.14, -0.14, -0.14],\n",
      "       [-0.14, -0.14, -0.14, ..., -0.14, -0.14, -0.14],\n",
      "       [-0.14, -0.14, -0.14, ..., -0.14, -0.14, -0.14],\n",
      "       ...,\n",
      "       [-0.14, -0.14, -0.14, ..., -0.14, -0.14, -0.14],\n",
      "       [-0.14, -0.14, -0.14, ..., -0.14, -0.14, -0.14],\n",
      "       [-0.14, -0.14, -0.14, ..., -0.14, -0.14, -0.14]], dtype=float32), 'sv_d3d': array([[-0.1, -0.1, -0.1, ..., -0.1, -0.1, -0.1],\n",
      "       [-0.1, -0.1, -0.1, ..., -0.1, -0.1, -0.1],\n",
      "       [-0.1, -0.1, -0.1, ..., -0.1, -0.1, -0.1],\n",
      "       ...,\n",
      "       [-0.1, -0.1, -0.1, ..., -0.1, -0.1, -0.1],\n",
      "       [-0.1, -0.1, -0.1, ..., -0.1, -0.1, -0.1],\n",
      "       [-0.1, -0.1, -0.1, ..., -0.1, -0.1, -0.1]], dtype=float32), 'sv_d3dsig': array([[-0.14, -0.14, -0.14, ..., -0.14, -0.14, -0.14],\n",
      "       [-0.14, -0.14, -0.14, ..., -0.14, -0.14, -0.14],\n",
      "       [-0.14, -0.14, -0.14, ..., -0.14, -0.14, -0.14],\n",
      "       ...,\n",
      "       [-0.14, -0.14, -0.14, ..., -0.14, -0.14, -0.14],\n",
      "       [-0.14, -0.14, -0.14, ..., -0.14, -0.14, -0.14],\n",
      "       [-0.14, -0.14, -0.14, ..., -0.14, -0.14, -0.14]], dtype=float32), 'sv_costhetasvpv': <Array [None, None, None, ... None, None, None] type='200 * option[var * float32]'>, 'sv_mask': array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "print(feature_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
