{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e43d484d",
   "metadata": {},
   "source": [
    "- make a histogram of the lepton pt as a regular variable,  the \"cut\" as a string category, the Z boson pt as another regular variable and finally the deltaR(Z boson, lepton) as another regular variable\n",
    "- save each of the selection cuts currently applied now as different masks\n",
    "- for each mask save the candidate lepton pT distribution in the histogram, save the cut in the string category, and save the Z boson pt, and the deltaR(z boson, candidate lepton)\n",
    "- for the Z boson pT you can do something similar to our gen matching i.e. find the Z boson gen particle in the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e99eb644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import uproot\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema, BaseSchema\n",
    "from coffea import nanoevents\n",
    "from coffea import processor\n",
    "import time\n",
    "\n",
    "import argparse\n",
    "import warnings\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "464f705f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import pickle as pkl\n",
    "import pyarrow as pa\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import pathlib\n",
    "from typing import List, Optional\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "from coffea import processor\n",
    "from coffea.nanoevents.methods import candidate, vector\n",
    "from coffea.analysis_tools import Weights, PackedSelection\n",
    "from boostedhiggs.utils import match_HWW\n",
    "from boostedhiggs.btag import btagWPs\n",
    "from boostedhiggs.btag import BTagCorrector\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Found duplicate branch \")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "np.seterr(invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a3118e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the configuration and processor\n",
    "fileset = {}\n",
    "fileset[\"DYJetsToLL_Pt-100To250\"] = [f\"../DY.root\"]\n",
    "\n",
    "job_name = '/0-1'\n",
    "channels=['ele', 'mu', 'had']\n",
    "\n",
    "from boostedhiggs.hwwprocessor_nocuts import HwwProcessor_nocuts\n",
    "p = HwwProcessor_nocuts(year='2017', channels=channels, output_location='./outfiles' + job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "56ceb951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove output directory to store fresh samples\n",
    "if os.path.exists('./outfiles'):\n",
    "    shutil.rmtree('./outfiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "577fde7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba82714a274148a9938e932cb304329e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/6 [00:00<?, ?chunk/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/coffea-env/lib/python3.7/site-packages/awkward/_connect/_numpy.py:210: RuntimeWarning: divide by zero encountered in log\n",
      "  *[nplike.asarray(x) for x in inputs], **kwargs\n"
     ]
    }
   ],
   "source": [
    "executor = processor.IterativeExecutor(status=True)\n",
    "run = processor.Runner(\n",
    "    executor=executor, savemetrics=True, schema=nanoevents.NanoAODSchema, chunksize=10000\n",
    ")\n",
    "    \n",
    "out, metrics = run(\n",
    "fileset, \"Events\", processor_instance=p\n",
    ")\n",
    "\n",
    "# dump to pickle\n",
    "filehandler = open('./outfiles/' + job_name + '.pkl', \"wb\")\n",
    "pkl.dump(out, filehandler)\n",
    "filehandler.close()\n",
    "\n",
    "# merge parquet\n",
    "for ch in channels:\n",
    "    data = pd.read_parquet('./outfiles/' + job_name + ch + '/parquet')\n",
    "    data.to_parquet('./outfiles/' + job_name + '_' + ch + '.parquet')\n",
    "\n",
    "    # remove old parquet files\n",
    "    os.system('rm -rf ./outfiles/' + job_name + ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "365aa16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for ch in channels:  \n",
    "    data[ch] = pq.read_table('./outfiles/' + job_name + '_' + ch + '.parquet').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1892311d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lep_pt', 'lep_isolation', 'lep_misolation', 'lep_fj_m',\n",
       "       'lep_fj_bjets_ophem', 'lep_fj_dr', 'fj_msoftdrop', 'fj_pt',\n",
       "       'lep_met_mt', 'met', 'ht', 'weight', 'trigger_iso', 'trigger_noiso',\n",
       "       'metfilters', 'leptonKin', 'oneMuon', 'oneElectron', 'notaus_mu',\n",
       "       'notaus_ele', 'MuonIsolation', 'ElectronIsolation', 'leptonInJet',\n",
       "       'anti_bjettag', 'mt_lep_met', 'oneFatjet', 'fatjetKin',\n",
       "       'fatjetSoftdrop', 'qcdrho'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ele'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f196c9",
   "metadata": {},
   "source": [
    "## Make histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2fba1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import shutil\n",
    "import pathlib\n",
    "from typing import List, Optional\n",
    "\n",
    "import argparse\n",
    "from coffea import processor\n",
    "from coffea.nanoevents.methods import candidate, vector\n",
    "from coffea.analysis_tools import Weights, PackedSelection\n",
    "\n",
    "import hist as hist2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import mplhep as hep\n",
    "from hist.intervals import clopper_pearson_interval\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Found duplicate branch \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a43ead30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the cuts\n",
    "cuts = {}\n",
    "\n",
    "cuts['ele'] = {'leptonKin': data['ele']['leptonKin']>40, \n",
    "               'oneElectron': data['ele']['oneElectron'],\n",
    "               'notaus_ele': data['ele']['notaus_ele'],\n",
    "               'ElectronIsolation': data['ele']['ElectronIsolation']==1,               \n",
    "               'leptonInJet': data['ele']['leptonInJet']==1,\n",
    "               'anti_bjettag': data['ele']['anti_bjettag']==1,\n",
    "               'ht': data['ele']['ht'],\n",
    "               'mt_lep_met': data['ele']['mt_lep_met']==1,               \n",
    "              }\n",
    "\n",
    "cuts['mu'] = {'leptonKin': data['mu']['leptonKin']>30, \n",
    "               'oneMuon': data['mu']['oneMuon'],\n",
    "               'notaus_mu': data['mu']['notaus_mu'],\n",
    "               'MuonIsolation': data['mu']['MuonIsolation']==1,                             \n",
    "               'leptonInJet': data['mu']['leptonInJet']==1,\n",
    "               'anti_bjettag': data['mu']['anti_bjettag']==1,\n",
    "               'ht': data['mu']['ht'],\n",
    "               'mt_lep_met': data['mu']['mt_lep_met']==1,               \n",
    "              }\n",
    "\n",
    "cuts['had'] = {'oneFatjet': data['had']['oneFatjet'], \n",
    "               'fatjetKin': data['had']['fatjetKin']>300,\n",
    "               'fatjetSoftdrop': data['had']['fatjetSoftdrop']==1,\n",
    "               'qcdrho': data['had']['qcdrho']==1,                             \n",
    "               'met': data['had']['met']<200,            \n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a8fc4fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = {}\n",
    "year = '2017'\n",
    "channels = ['ele', 'mu']\n",
    "\n",
    "hists[year] = {}\n",
    "for ch in channels:\n",
    "\n",
    "    hists[year][ch] = hist2.Hist(\n",
    "        hist2.axis.Regular(50,0, 250, name='lepton_pt', label='lepton_pt', flow=False),\n",
    "        hist2.axis.StrCategory([], name='cuts', growth=True)\n",
    "    )\n",
    "\n",
    "# loop over the cuts and fill the histograms\n",
    "for ch in channels:\n",
    "    for key, value in cuts[ch].items():\n",
    "        hists[year][ch].fill(\n",
    "            data[ch][value]['lep_pt'], key,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e0629a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "odir = './plots3'\n",
    "# remove output directory to store fresh samples\n",
    "if os.path.exists(f'{odir}'):\n",
    "    shutil.rmtree(f'{odir}')\n",
    "for ch in channels:\n",
    "    for cut in hists[year][ch].axes[-1]:\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        hep.histplot(hists[year][ch][{'cuts': cut}], ax=ax)\n",
    "        ax.set_xlabel(f\"{'lep_pt'}\")\n",
    "        ax.set_title(f'{ch} channel after \\n {cut} cut')\n",
    "        hep.cms.lumitext(f\"{year} (13 TeV)\", ax=ax)\n",
    "        hep.cms.text(\"Work in Progress\", ax=ax)\n",
    "\n",
    "        if not os.path.exists(f'{odir}/'):\n",
    "            os.makedirs(f'{odir}/')\n",
    "\n",
    "        plt.savefig(f'{odir}/{ch}_{cut}.pdf')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f2224514",
   "metadata": {},
   "outputs": [],
   "source": [
    "odir = './plots2'\n",
    "# remove output directory to store fresh samples\n",
    "if os.path.exists(f'{odir}'):\n",
    "    shutil.rmtree(f'{odir}')\n",
    "for ch in channels:\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        for cut in hists[year][ch].axes[-1]:        \n",
    "            hep.histplot(hists[year][ch][{'cuts': cut}], ax=ax, label=cut)\n",
    "        \n",
    "        ax.set_xlabel(f\"{'lep_pt'}\")\n",
    "        ax.set_title(f'{ch} channel after \\n {cut} cut')\n",
    "        hep.cms.lumitext(f\"{year} (13 TeV)\", ax=ax)\n",
    "        hep.cms.text(\"Work in Progress\", ax=ax)\n",
    "\n",
    "        if not os.path.exists(f'{odir}/'):\n",
    "            os.makedirs(f'{odir}/')\n",
    "        ax.legend()\n",
    "        plt.savefig(f'{odir}/{ch}_{cut}.pdf')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a0ff0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffea-env",
   "language": "python",
   "name": "coffea-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
