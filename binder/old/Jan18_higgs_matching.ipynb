{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import uproot\n",
    "import pickle as pkl\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import awkward as ak\n",
    "from coffea import processor\n",
    "from coffea import nanoevents\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema, BaseSchema\n",
    "from coffea.nanoevents.methods import candidate, vector\n",
    "from coffea.analysis_tools import Weights, PackedSelection\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Found duplicate branch \")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "np.seterr(invalid='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_val(\n",
    "    arr: ak.Array,\n",
    "    value: float,\n",
    "    target: int = None,\n",
    "    axis: int = 0,\n",
    "    to_numpy: bool = False,\n",
    "    clip: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    basically: preserves the nested structure of the ak array and replaces None values with -1\n",
    "    pads awkward array up to ``target`` index along axis ``axis`` with value ``value``,\n",
    "    optionally converts to numpy array\n",
    "    \"\"\"\n",
    "    if target:\n",
    "        ret = ak.fill_none(ak.pad_none(arr, target, axis=axis, clip=clip), value, axis=None)\n",
    "    else:\n",
    "        ret = ak.fill_none(arr, value, axis=None)\n",
    "    return ret.to_numpy() if to_numpy else ret\n",
    "\n",
    "def build_p4(cand):\n",
    "    return ak.zip(\n",
    "        {\n",
    "            \"pt\": cand.pt,\n",
    "            \"eta\": cand.eta,\n",
    "            \"phi\": cand.phi,\n",
    "            \"mass\": cand.mass,\n",
    "            \"charge\": cand.charge,\n",
    "        },\n",
    "        with_name=\"PtEtaPhiMCandidate\",\n",
    "        behavior=candidate.behavior,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_PDGID = 1\n",
    "c_PDGID = 4\n",
    "b_PDGID = 5\n",
    "g_PDGID = 21\n",
    "TOP_PDGID = 6\n",
    "\n",
    "ELE_PDGID = 11\n",
    "vELE_PDGID = 12\n",
    "MU_PDGID = 13\n",
    "vMU_PDGID = 14\n",
    "TAU_PDGID = 15\n",
    "vTAU_PDGID = 16\n",
    "\n",
    "Z_PDGID = 23\n",
    "W_PDGID = 24\n",
    "HIGGS_PDGID = 25\n",
    "\n",
    "def getParticles(\n",
    "    genparticles, lowid=22, highid=25, flags=[\"fromHardProcess\", \"isLastCopy\"]\n",
    "):\n",
    "    \"\"\"\n",
    "    returns the particle objects that satisfy a low id,\n",
    "    high id condition and have certain flags\n",
    "    \"\"\"\n",
    "    absid = abs(genparticles.pdgId)\n",
    "    return genparticles[\n",
    "        ((absid >= lowid) & (absid <= highid)) & genparticles.hasFlags(flags)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a signal file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of events per file is 98400\n"
     ]
    }
   ],
   "source": [
    "# load a root file into coffea-friendly NanoAOD structure\n",
    "import uproot\n",
    "f = uproot.open(f\"./sig.root\")\n",
    "num = f['Events'].num_entries   ### checks number of events per file \n",
    "\n",
    "events = nanoevents.NanoEventsFactory.from_root(f, \"Events\").events()\n",
    "nevents = len(events)\n",
    "\n",
    "print(f'number of events per file is {nevents}')\n",
    "\n",
    "genparticles = events.GenPart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### define helper functions that select candidate lepton and candidate jet\n",
    "\n",
    "def get_candidatelep(events):   \n",
    "    # muons\n",
    "    good_muons = (\n",
    "        (events.Muon.pt > 30)\n",
    "        & (np.abs(events.Muon.eta) < 2.4)\n",
    "        & (np.abs(events.Muon.dz) < 0.1)\n",
    "        & (np.abs(events.Muon.dxy) < 0.05)\n",
    "        & (events.Muon.sip3d <= 4.0)\n",
    "        & events.Muon.mediumId\n",
    "    )\n",
    "\n",
    "    # electrons\n",
    "    good_electrons = (\n",
    "        (events.Electron.pt > 38)\n",
    "        & (np.abs(events.Electron.eta) < 2.4)\n",
    "        & ((np.abs(events.Electron.eta) < 1.44) | (np.abs(events.Electron.eta) > 1.57))\n",
    "        & (np.abs(events.Electron.dz) < 0.1)\n",
    "        & (np.abs(events.Electron.dxy) < 0.05)\n",
    "        & (events.Electron.sip3d <= 4.0)\n",
    "        & (events.Electron.mvaFall17V2noIso_WP90)\n",
    "    )\n",
    "\n",
    "    # get candidate lepton\n",
    "    goodleptons = ak.concatenate(\n",
    "        [events.Muon[good_muons], events.Electron[good_electrons]], axis=1\n",
    "    )  # concat muons and electrons\n",
    "    goodleptons = goodleptons[ak.argsort(goodleptons.pt, ascending=False)]  # sort by pt\n",
    "    candidatelep = ak.firsts(goodleptons)  # pick highest pt\n",
    "\n",
    "    return candidatelep\n",
    "\n",
    "def get_candidatefj(events, candidatelep):  \n",
    "    candidatelep_p4 = build_p4(candidatelep)  # build p4 for candidate lepton\n",
    "\n",
    "    # fatjets\n",
    "    fatjets = events.FatJet\n",
    "\n",
    "    good_fatjets = (fatjets.pt > 200) & (abs(fatjets.eta) < 2.5) & fatjets.isTight\n",
    "    good_fatjets = fatjets[good_fatjets]  # select good fatjets\n",
    "    good_fatjets = good_fatjets[ak.argsort(good_fatjets.pt, ascending=False)]  # sort them by pt\n",
    "\n",
    "    # for leptonic channel: first clean jets and leptons by removing overlap, then pick candidate_fj closest to the lepton\n",
    "    lep_in_fj_overlap_bool = good_fatjets.delta_r(candidatelep_p4) > 0.1\n",
    "    good_fatjets = good_fatjets[lep_in_fj_overlap_bool]\n",
    "    fj_idx_lep = ak.argmin(good_fatjets.delta_r(candidatelep_p4), axis=1, keepdims=True)\n",
    "    candidatefj = ak.firsts(good_fatjets[fj_idx_lep])\n",
    "\n",
    "    return candidatefj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct matching function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select candidate fj\n",
    "candidatelep = get_candidatelep(events)\n",
    "candidatefj = get_candidatefj(events, candidatelep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select Higgs particles that decay to W from the full set\n",
    "higgs = getParticles(genparticles, 25)\n",
    "is_hWW = ak.all(\n",
    "    abs(higgs.children.pdgId) == 24, axis=2\n",
    ")  # W~24 so we get H->WW (limitation: only picking one W and assumes the other will be there)\n",
    "\n",
    "higgs = higgs[is_hWW]\n",
    "\n",
    "# choose higgs closest to fj\n",
    "matched_higgs = candidatefj.nearest(higgs, axis=1, threshold=0.8)\n",
    "matched_higgs_children = matched_higgs.children\n",
    "children_mass = matched_higgs_children.mass\n",
    "\n",
    "# get WW daughters\n",
    "daughters = ak.flatten(\n",
    "    ak.flatten(matched_higgs_children.distinctChildren, axis=2), axis=2\n",
    ")\n",
    "\n",
    "# make sure the daughters come from hard process\n",
    "GEN_FLAGS = [\"fromHardProcess\", \"isLastCopy\"]\n",
    "daughters = daughters[daughters.hasFlags(GEN_FLAGS)]\n",
    "daughters_pdgId = abs(daughters.pdgId)\n",
    "\n",
    "decay = (\n",
    "    # 2 quarks * 1\n",
    "    (ak.sum(daughters_pdgId <= b_PDGID, axis=1) == 2) * 1\n",
    "    # 1 electron * 3\n",
    "    + (ak.sum(daughters_pdgId == ELE_PDGID, axis=1) == 1) * 3\n",
    "    # 1 muon * 5\n",
    "    + (ak.sum(daughters_pdgId == MU_PDGID, axis=1) == 1) * 5\n",
    "    # 1 tau * 7\n",
    "    + (ak.sum(daughters_pdgId == TAU_PDGID, axis=1) == 1) * 7\n",
    "    # 4 quarks * 11\n",
    "    + (ak.sum(daughters_pdgId <= b_PDGID, axis=1) == 4) * 11\n",
    "    # 3 quarks * 13\n",
    "    + (ak.sum(daughters_pdgId <= b_PDGID, axis=1) == 3) * 13\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of c-quarks [0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, ... 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "### get number of c-quarks\n",
    "prompt_c = getParticles(\n",
    "    genparticles, c_PDGID, c_PDGID, [\"fromHardProcess\", \"isLastCopy\"]\n",
    ")\n",
    "prompt_c = prompt_c[abs(prompt_c.distinctParent.pdgId) == 24]  # parent W\n",
    "n_cquarks = ak.sum(prompt_c.pt > 0, axis=1)\n",
    "print(f\"number of c-quarks {n_cquarks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "events with one muon and 1 quark \n",
      " [0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, ... 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "events with one muon and 0 quark (c-quark) \n",
      " [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, ... 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "events with one muon and 1 quark (c-quark) \n",
      " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ... 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def to_label(array: ak.Array) -> ak.Array:\n",
    "    return ak.values_astype(array, np.int32)\n",
    "\n",
    "a = to_label(decay == 6)  # 1 electron && 1 quark\n",
    "print(f\"events with one muon and 1 quark \\n {a[~ak.is_none(a)]}\")\n",
    "\n",
    "a = to_label((decay == 6) & (n_cquarks == 0)) # 1 electron && 1 quark && 0 c quarks\n",
    "print(f\"events with one muon and 0 quark (c-quark) \\n {a[~ak.is_none(a)]}\")\n",
    "\n",
    "a = to_label((decay == 6) & (n_cquarks == 1)) # 1 electron && 1 quark && 1 c quark\n",
    "print(f\"events with one muon and 1 quark (c-quark) \\n {a[~ak.is_none(a)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### with this in mind we can build the array of classes\n",
    "\n",
    "genLabelVars = {\n",
    "    \"label_H_WqqWqq_0c\": to_label((decay == 11) & (n_cquarks == 0)),\n",
    "    \"label_H_WqqWqq_1c\": to_label((decay == 11) & (n_cquarks == 1)),\n",
    "    \"label_H_WqqWqq_2c\": to_label((decay == 11) & (n_cquarks == 2)),\n",
    "    \"label_H_WqqWq_0c\": to_label((decay == 13) & (n_cquarks == 0)),\n",
    "    \"label_H_WqqWq_1c\": to_label((decay == 13) & (n_cquarks == 1)),\n",
    "    \"label_H_WqqWq_2c\": to_label((decay == 13) & (n_cquarks == 2)),\n",
    "    \"label_H_WqqWev_0c\": to_label((decay == 4) & (n_cquarks == 0)),\n",
    "    \"label_H_WqqWev_1c\": to_label((decay == 4) & (n_cquarks == 1)),\n",
    "    \"label_H_WqqWmv_0c\": to_label((decay == 6) & (n_cquarks == 0)),\n",
    "    \"label_H_WqqWmv_1c\": to_label((decay == 6) & (n_cquarks == 1)),\n",
    "\n",
    "    # \"label_H_WqqWtauhv_0c\": to_label(decay == 11),  # force c=0\n",
    "    # \"label_H_WqqWtauhv_1c\": to_label(decay == 11),  # force c=1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffea-env",
   "language": "python",
   "name": "coffea-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
